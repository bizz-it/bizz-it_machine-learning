{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 22:25:07.838074: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-16 22:25:07.870362: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-16 22:25:07.871159: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-16 22:25:08.860964: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_logo_detector.ipynb  file0.jpeg\t       output\t\t testing.ipynb\n",
      "exporter_main_v2.py\t    model_main_tf2.py  ssd_mobilenet_v2\n"
     ]
    }
   ],
   "source": [
    "!cd ..\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-16 20:34:12.869693: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-16 20:34:13.066074: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-16 20:34:13.067293: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-16 20:34:14.481402: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "2023-05-16 20:34:17.297318: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-16 20:34:17.298071: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "W0516 20:34:17.301898 140536734373696 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "I0516 20:34:17.323006 140536734373696 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: None\n",
      "I0516 20:34:17.325763 140536734373696 config_util.py:552] Maybe overwriting train_steps: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0516 20:34:17.325865 140536734373696 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0516 20:34:17.358048 140536734373696 deprecation.py:364] From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['/home/irizqy/ml_ws/bangkit-ws/data/train.record']\n",
      "I0516 20:34:17.366542 140536734373696 dataset_builder.py:162] Reading unweighted datasets: ['/home/irizqy/ml_ws/bangkit-ws/data/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['/home/irizqy/ml_ws/bangkit-ws/data/train.record']\n",
      "I0516 20:34:17.366748 140536734373696 dataset_builder.py:79] Reading record datasets for input file: ['/home/irizqy/ml_ws/bangkit-ws/data/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0516 20:34:17.366836 140536734373696 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0516 20:34:17.366965 140536734373696 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0516 20:34:17.374961 140536734373696 deprecation.py:364] From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0516 20:34:17.390909 140536734373696 deprecation.py:364] From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "2023-05-16 20:34:18.910560: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'cond/SparseToDense/ParseSingleExample/ParseExample/ParseExampleV2_1' with dtype int64 and shape [1]\n",
      "\t [[{{node cond/SparseToDense/ParseSingleExample/ParseExample/ParseExampleV2_1}}]]\n",
      "2023-05-16 20:34:18.910671: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'cond/SparseToDense/ParseSingleExample/ParseExample/ParseExampleV2_1' with dtype int64 and shape [1]\n",
      "\t [[{{node cond/SparseToDense/ParseSingleExample/ParseExample/ParseExampleV2_1}}]]\n",
      "2023-05-16 20:34:18.923319: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'cond_1/SparseToDense/ParseSingleExample/ParseExample/ParseExampleV2_1' with dtype int64 and shape [1]\n",
      "\t [[{{node cond_1/SparseToDense/ParseSingleExample/ParseExample/ParseExampleV2_1}}]]\n",
      "2023-05-16 20:34:18.923420: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'cond_1/SparseToDense/ParseSingleExample/ParseExample/ParseExampleV2_1' with dtype int64 and shape [1]\n",
      "\t [[{{node cond_1/SparseToDense/ParseSingleExample/ParseExample/ParseExampleV2_1}}]]\n",
      "WARNING:tensorflow:From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0516 20:34:23.233038 140536734373696 deprecation.py:364] From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0516 20:34:26.142718 140536734373696 deprecation.py:364] From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0516 20:34:28.455362 140536734373696 deprecation.py:364] From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/object_detection/builders/optimizer_builder.py:124: The name tf.keras.optimizers.SGD is deprecated. Please use tf.keras.optimizers.legacy.SGD instead.\n",
      "\n",
      "W0516 20:34:30.426904 140536734373696 module_wrapper.py:149] From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/object_detection/builders/optimizer_builder.py:124: The name tf.keras.optimizers.SGD is deprecated. Please use tf.keras.optimizers.legacy.SGD instead.\n",
      "\n",
      "2023-05-16 20:34:30.465922: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_24' with dtype resource\n",
      "\t [[{{node Placeholder/_24}}]]\n",
      "2023-05-16 20:34:30.466551: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-16 20:34:31.067242: W tensorflow/core/framework/dataset.cc:807] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-05-16 20:34:31.067767: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-16 20:34:31.274326: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): CANCELLED: GetNextFromShard was cancelled\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2023-05-16 20:34:31.274608: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): CANCELLED: GetNextFromShard was cancelled\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]] [type.googleapis.com/tensorflow.DerivedStatus='']\n",
      "/home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/keras/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n",
      "I0516 20:34:35.917263 140530340042496 api.py:459] feature_map_spatial_dims: [(20, 20), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0516 20:34:37.271077 140530340042496 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0516 20:34:37.271239 140530340042496 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0516 20:34:37.271323 140530340042496 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0516 20:34:37.271398 140530340042496 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0516 20:34:37.271470 140530340042496 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0516 20:34:37.271544 140530340042496 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "I0516 20:34:46.643800 140530340042496 api.py:459] feature_map_spatial_dims: [(20, 20), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
      "2023-05-16 20:34:56.345245: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_29' with dtype int64\n",
      "\t [[{{node Placeholder/_29}}]]\n",
      "2023-05-16 20:34:56.345685: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_22' with dtype resource\n",
      "\t [[{{node Placeholder/_22}}]]\n",
      "2023-05-16 20:34:56.929941: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "WARNING:tensorflow:From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0516 20:34:57.913043 140530365220608 deprecation.py:569] From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "I0516 20:34:58.946891 140530365220608 api.py:459] feature_map_spatial_dims: [(20, 20), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
      "I0516 20:35:07.891479 140530365220608 api.py:459] feature_map_spatial_dims: [(20, 20), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
      "I0516 20:35:15.501257 140530365220608 api.py:459] feature_map_spatial_dims: [(20, 20), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
      "I0516 20:35:23.354487 140530365220608 api.py:459] feature_map_spatial_dims: [(20, 20), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
      "INFO:tensorflow:Step 100 per-step time 3.427s\n",
      "I0516 20:40:40.114537 140536734373696 model_lib_v2.py:705] Step 100 per-step time 3.427s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.20929235,\n",
      " 'Loss/localization_loss': 0.13245745,\n",
      " 'Loss/regularization_loss': 0.08559628,\n",
      " 'Loss/total_loss': 0.42734605,\n",
      " 'learning_rate': 0.02916656}\n",
      "I0516 20:40:40.115526 140536734373696 model_lib_v2.py:708] {'Loss/classification_loss': 0.20929235,\n",
      " 'Loss/localization_loss': 0.13245745,\n",
      " 'Loss/regularization_loss': 0.08559628,\n",
      " 'Loss/total_loss': 0.42734605,\n",
      " 'learning_rate': 0.02916656}\n",
      "INFO:tensorflow:Step 200 per-step time 2.988s\n",
      "I0516 20:45:38.873779 140536734373696 model_lib_v2.py:705] Step 200 per-step time 2.988s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.20168294,\n",
      " 'Loss/localization_loss': 0.10438756,\n",
      " 'Loss/regularization_loss': 0.08614235,\n",
      " 'Loss/total_loss': 0.39221287,\n",
      " 'learning_rate': 0.05}\n",
      "I0516 20:45:38.873977 140536734373696 model_lib_v2.py:708] {'Loss/classification_loss': 0.20168294,\n",
      " 'Loss/localization_loss': 0.10438756,\n",
      " 'Loss/regularization_loss': 0.08614235,\n",
      " 'Loss/total_loss': 0.39221287,\n",
      " 'learning_rate': 0.05}\n",
      "INFO:tensorflow:Step 300 per-step time 3.108s\n",
      "I0516 20:50:49.717359 140536734373696 model_lib_v2.py:705] Step 300 per-step time 3.108s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2347991,\n",
      " 'Loss/localization_loss': 0.08758823,\n",
      " 'Loss/regularization_loss': 0.08671065,\n",
      " 'Loss/total_loss': 0.40909797,\n",
      " 'learning_rate': 0.0375}\n",
      "I0516 20:50:49.717540 140536734373696 model_lib_v2.py:708] {'Loss/classification_loss': 0.2347991,\n",
      " 'Loss/localization_loss': 0.08758823,\n",
      " 'Loss/regularization_loss': 0.08671065,\n",
      " 'Loss/total_loss': 0.40909797,\n",
      " 'learning_rate': 0.0375}\n",
      "INFO:tensorflow:Step 400 per-step time 3.108s\n",
      "I0516 20:56:00.553548 140536734373696 model_lib_v2.py:705] Step 400 per-step time 3.108s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12895902,\n",
      " 'Loss/localization_loss': 0.074286684,\n",
      " 'Loss/regularization_loss': 0.08674853,\n",
      " 'Loss/total_loss': 0.28999424,\n",
      " 'learning_rate': 0.012499998}\n",
      "I0516 20:56:00.553741 140536734373696 model_lib_v2.py:708] {'Loss/classification_loss': 0.12895902,\n",
      " 'Loss/localization_loss': 0.074286684,\n",
      " 'Loss/regularization_loss': 0.08674853,\n",
      " 'Loss/total_loss': 0.28999424,\n",
      " 'learning_rate': 0.012499998}\n",
      "INFO:tensorflow:Step 500 per-step time 3.111s\n",
      "I0516 21:01:11.695029 140536734373696 model_lib_v2.py:705] Step 500 per-step time 3.111s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08114573,\n",
      " 'Loss/localization_loss': 0.032517657,\n",
      " 'Loss/regularization_loss': 0.08672234,\n",
      " 'Loss/total_loss': 0.20038573,\n",
      " 'learning_rate': 0.0}\n",
      "I0516 21:01:11.695207 140536734373696 model_lib_v2.py:708] {'Loss/classification_loss': 0.08114573,\n",
      " 'Loss/localization_loss': 0.032517657,\n",
      " 'Loss/regularization_loss': 0.08672234,\n",
      " 'Loss/total_loss': 0.20038573,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 600 per-step time 3.110s\n",
      "I0516 21:06:22.726223 140536734373696 model_lib_v2.py:705] Step 600 per-step time 3.110s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09825727,\n",
      " 'Loss/localization_loss': 0.032184657,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.2171641,\n",
      " 'learning_rate': 0.0}\n",
      "I0516 21:06:22.726427 140536734373696 model_lib_v2.py:708] {'Loss/classification_loss': 0.09825727,\n",
      " 'Loss/localization_loss': 0.032184657,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.2171641,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 700 per-step time 3.133s\n",
      "I0516 21:11:36.042968 140536734373696 model_lib_v2.py:705] Step 700 per-step time 3.133s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.092020415,\n",
      " 'Loss/localization_loss': 0.03621312,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.2149557,\n",
      " 'learning_rate': 0.0}\n",
      "I0516 21:11:36.043161 140536734373696 model_lib_v2.py:708] {'Loss/classification_loss': 0.092020415,\n",
      " 'Loss/localization_loss': 0.03621312,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.2149557,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 800 per-step time 3.148s\n",
      "I0516 21:16:50.827033 140536734373696 model_lib_v2.py:705] Step 800 per-step time 3.148s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08822106,\n",
      " 'Loss/localization_loss': 0.027467158,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.20241039,\n",
      " 'learning_rate': 0.0}\n",
      "I0516 21:16:50.827213 140536734373696 model_lib_v2.py:708] {'Loss/classification_loss': 0.08822106,\n",
      " 'Loss/localization_loss': 0.027467158,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.20241039,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 900 per-step time 3.123s\n",
      "I0516 21:22:03.115404 140536734373696 model_lib_v2.py:705] Step 900 per-step time 3.123s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07180174,\n",
      " 'Loss/localization_loss': 0.025810964,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.18433487,\n",
      " 'learning_rate': 0.0}\n",
      "I0516 21:22:03.115609 140536734373696 model_lib_v2.py:708] {'Loss/classification_loss': 0.07180174,\n",
      " 'Loss/localization_loss': 0.025810964,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.18433487,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 1000 per-step time 3.131s\n",
      "I0516 21:27:16.205550 140536734373696 model_lib_v2.py:705] Step 1000 per-step time 3.131s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09095841,\n",
      " 'Loss/localization_loss': 0.03494058,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.21262117,\n",
      " 'learning_rate': 0.0}\n",
      "I0516 21:27:16.205755 140536734373696 model_lib_v2.py:708] {'Loss/classification_loss': 0.09095841,\n",
      " 'Loss/localization_loss': 0.03494058,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.21262117,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 1100 per-step time 3.126s\n",
      "I0516 21:32:28.819721 140536734373696 model_lib_v2.py:705] Step 1100 per-step time 3.126s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09241585,\n",
      " 'Loss/localization_loss': 0.03416577,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.21330377,\n",
      " 'learning_rate': 0.0}\n",
      "I0516 21:32:28.819921 140536734373696 model_lib_v2.py:708] {'Loss/classification_loss': 0.09241585,\n",
      " 'Loss/localization_loss': 0.03416577,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.21330377,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 1200 per-step time 3.123s\n",
      "I0516 21:37:41.147554 140536734373696 model_lib_v2.py:705] Step 1200 per-step time 3.123s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13436568,\n",
      " 'Loss/localization_loss': 0.05345327,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.2745411,\n",
      " 'learning_rate': 0.0}\n",
      "I0516 21:37:41.147798 140536734373696 model_lib_v2.py:708] {'Loss/classification_loss': 0.13436568,\n",
      " 'Loss/localization_loss': 0.05345327,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.2745411,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 1300 per-step time 3.100s\n",
      "I0516 21:42:51.123887 140536734373696 model_lib_v2.py:705] Step 1300 per-step time 3.100s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08300852,\n",
      " 'Loss/localization_loss': 0.031361006,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.2010917,\n",
      " 'learning_rate': 0.0}\n",
      "I0516 21:42:51.124089 140536734373696 model_lib_v2.py:708] {'Loss/classification_loss': 0.08300852,\n",
      " 'Loss/localization_loss': 0.031361006,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.2010917,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 1400 per-step time 3.126s\n",
      "I0516 21:48:03.717601 140536734373696 model_lib_v2.py:705] Step 1400 per-step time 3.126s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08283833,\n",
      " 'Loss/localization_loss': 0.03174069,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.20130119,\n",
      " 'learning_rate': 0.0}\n",
      "I0516 21:48:03.717785 140536734373696 model_lib_v2.py:708] {'Loss/classification_loss': 0.08283833,\n",
      " 'Loss/localization_loss': 0.03174069,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.20130119,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 1500 per-step time 3.128s\n",
      "I0516 21:53:16.554906 140536734373696 model_lib_v2.py:705] Step 1500 per-step time 3.128s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.097865306,\n",
      " 'Loss/localization_loss': 0.04858911,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.23317659,\n",
      " 'learning_rate': 0.0}\n",
      "I0516 21:53:16.555104 140536734373696 model_lib_v2.py:708] {'Loss/classification_loss': 0.097865306,\n",
      " 'Loss/localization_loss': 0.04858911,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.23317659,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 1600 per-step time 3.129s\n",
      "I0516 21:58:29.501812 140536734373696 model_lib_v2.py:705] Step 1600 per-step time 3.129s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08556818,\n",
      " 'Loss/localization_loss': 0.033012982,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.20530334,\n",
      " 'learning_rate': 0.0}\n",
      "I0516 21:58:29.501995 140536734373696 model_lib_v2.py:708] {'Loss/classification_loss': 0.08556818,\n",
      " 'Loss/localization_loss': 0.033012982,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.20530334,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 1700 per-step time 3.124s\n",
      "I0516 22:03:41.923487 140536734373696 model_lib_v2.py:705] Step 1700 per-step time 3.124s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07667536,\n",
      " 'Loss/localization_loss': 0.028060982,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.19145851,\n",
      " 'learning_rate': 0.0}\n",
      "I0516 22:03:41.923688 140536734373696 model_lib_v2.py:708] {'Loss/classification_loss': 0.07667536,\n",
      " 'Loss/localization_loss': 0.028060982,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.19145851,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 1800 per-step time 3.120s\n",
      "I0516 22:08:53.945731 140536734373696 model_lib_v2.py:705] Step 1800 per-step time 3.120s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1401433,\n",
      " 'Loss/localization_loss': 0.037805777,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.26467124,\n",
      " 'learning_rate': 0.0}\n",
      "I0516 22:08:53.945916 140536734373696 model_lib_v2.py:708] {'Loss/classification_loss': 0.1401433,\n",
      " 'Loss/localization_loss': 0.037805777,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.26467124,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 1900 per-step time 3.113s\n",
      "I0516 22:14:05.229521 140536734373696 model_lib_v2.py:705] Step 1900 per-step time 3.113s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1633231,\n",
      " 'Loss/localization_loss': 0.056548998,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.30659425,\n",
      " 'learning_rate': 0.0}\n",
      "I0516 22:14:05.229715 140536734373696 model_lib_v2.py:708] {'Loss/classification_loss': 0.1633231,\n",
      " 'Loss/localization_loss': 0.056548998,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.30659425,\n",
      " 'learning_rate': 0.0}\n",
      "INFO:tensorflow:Step 2000 per-step time 3.110s\n",
      "I0516 22:19:16.277733 140536734373696 model_lib_v2.py:705] Step 2000 per-step time 3.110s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09759015,\n",
      " 'Loss/localization_loss': 0.031213814,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.21552613,\n",
      " 'learning_rate': 0.0}\n",
      "I0516 22:19:16.277909 140536734373696 model_lib_v2.py:708] {'Loss/classification_loss': 0.09759015,\n",
      " 'Loss/localization_loss': 0.031213814,\n",
      " 'Loss/regularization_loss': 0.086722165,\n",
      " 'Loss/total_loss': 0.21552613,\n",
      " 'learning_rate': 0.0}\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python model_main_tf2.py --model_dir=output/ --pipeline_config_path=ssd_mobilenet_v2/pipeline.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irizqy/ml_ws/bangkit-ws/bin/python: /home/irizqy/ml_ws/bangkit-ws/bin/python: cannot execute binary file\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'--pipeline_config_path ssd_mobilenet_v2/pipeline.config //\\n--trained_checkpoint_dir output/ //\\n--output_directory ssd_mobilenet_v2_ft \\n'' returned non-zero exit status 126.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_cell_magic(\u001b[39m'\u001b[39;49m\u001b[39mbash\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mpython exporter_main_v2.py --input_type image_tensor //\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m--pipeline_config_path ssd_mobilenet_v2/pipeline.config //\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m--trained_checkpoint_dir output/ //\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m--output_directory ssd_mobilenet_v2_ft \u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/ml_ws/bangkit-ws/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2478\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2476\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2477\u001b[0m     args \u001b[39m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2478\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2480\u001b[0m \u001b[39m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2481\u001b[0m \u001b[39m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2482\u001b[0m \u001b[39m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(fn, magic\u001b[39m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/ml_ws/bangkit-ws/lib/python3.9/site-packages/IPython/core/magics/script.py:154\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     line \u001b[39m=\u001b[39m script\n\u001b[0;32m--> 154\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshebang(line, cell)\n",
      "File \u001b[0;32m~/ml_ws/bangkit-ws/lib/python3.9/site-packages/IPython/core/magics/script.py:314\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mraise_error \u001b[39mand\u001b[39;00m p\u001b[39m.\u001b[39mreturncode \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    310\u001b[0m     \u001b[39m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     \u001b[39m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    313\u001b[0m     rc \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39mreturncode \u001b[39mor\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m9\u001b[39m\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'--pipeline_config_path ssd_mobilenet_v2/pipeline.config //\\n--trained_checkpoint_dir output/ //\\n--output_directory ssd_mobilenet_v2_ft \\n'' returned non-zero exit status 126."
     ]
    }
   ],
   "source": [
    "!python src/exporter_main_v2.py --input_type image_tensor --pipeline_config_path src/ssd_mobilenet_v2/pipeline.config --trained_checkpoint_dir src/output/ --output_directory src/ssd_mobilenet_v2_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_MODEL_DIR = 'ssd_mobilenet_v2_ft/'\n",
    "PATH_TO_LABELS = '/home/irizqy/ml_ws/bangkit-ws/data/label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 22:25:13.205466: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-16 22:25:13.206053: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 8.241688013076782 seconds\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"saved_model\"\n",
    "\n",
    "print('Loading model...', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# Load saved model and build the detection function\n",
    "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                    use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATHS = ['/home/irizqy/ml_ws/bangkit-ws/data/bizit-dev_test-data/32_IMG20230504165642.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference for /home/irizqy/ml_ws/bangkit-ws/data/bizit-dev_test-data/32_IMG20230504165642.jpg... Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
    "count = 0\n",
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "    \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "    Puts image into numpy array to feed into tensorflow graph.\n",
    "    Note that by convention we put it into a numpy array with shape\n",
    "    (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "    Args:\n",
    "      path: the file path to the image\n",
    "\n",
    "    Returns:\n",
    "      uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    \"\"\"\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "\n",
    "for image_path in IMAGE_PATHS:\n",
    "\n",
    "    print('Running inference for {}... '.format(image_path), end='')\n",
    "\n",
    "    image_np = load_image_into_numpy_array(image_path)\n",
    "    \n",
    "    if image_np.shape[2] == 4:\n",
    "        image_np = image_np[:, :, :3]\n",
    "\n",
    "    # Things to try:\n",
    "    # Flip horizontally\n",
    "    # image_np = np.fliplr(image_np).copy()\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    # image_np = np.tile(\n",
    "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
    "\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image_np)\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    # input_tensor = np.expand_dims(image_np, 0)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                   for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np_with_detections,\n",
    "          detections['detection_boxes'],\n",
    "          detections['detection_classes'],\n",
    "          detections['detection_scores'],\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=200,\n",
    "          min_score_thresh=.30,\n",
    "          agnostic_mode=False)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(image_np_with_detections)\n",
    "    im = Image.fromarray(image_np_with_detections)\n",
    "    im.save(f\"file{count}.jpeg\")\n",
    "    count+=1\n",
    "    print('Done')\n",
    "    plt.show()\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bangkit-ws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
