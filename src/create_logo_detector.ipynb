{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 17:52:01.604426: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-21 17:52:01.643797: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-21 17:52:01.649912: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-21 17:52:02.482322: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad_example.jpeg\t    good_example.jpeg\t       ssd_mobilenet_v2\n",
      "create_logo_detector.ipynb  model_main_tf2.py\t       ssd_mobilenet_v2_ft\n",
      "cropped-logo.jpg\t    no_detection_example.jpeg  ssd_mobilenet_v2_ft2\n",
      "detected-logo0.jpeg\t    output\t\t       testing.ipynb\n",
      "exporter_main_v2.py\t    _ssd_mobilenet_v2\t       test.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-21 13:32:44.138422: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-21 13:32:44.203842: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-21 13:32:44.204146: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-21 13:32:45.274726: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "2023-05-21 13:32:47.781335: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-21 13:32:47.782328: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "W0521 13:32:47.784214 140565636405056 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "I0521 13:32:47.799067 140565636405056 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: None\n",
      "I0521 13:32:47.802287 140565636405056 config_util.py:552] Maybe overwriting train_steps: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0521 13:32:47.802359 140565636405056 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0521 13:32:47.840607 140565636405056 deprecation.py:364] From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['/home/irizqy/ml_ws/bangkit-ws/data/train.record']\n",
      "I0521 13:32:47.846427 140565636405056 dataset_builder.py:162] Reading unweighted datasets: ['/home/irizqy/ml_ws/bangkit-ws/data/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['/home/irizqy/ml_ws/bangkit-ws/data/train.record']\n",
      "I0521 13:32:47.846627 140565636405056 dataset_builder.py:79] Reading record datasets for input file: ['/home/irizqy/ml_ws/bangkit-ws/data/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0521 13:32:47.846691 140565636405056 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0521 13:32:47.846793 140565636405056 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0521 13:32:47.851715 140565636405056 deprecation.py:364] From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0521 13:32:47.866319 140565636405056 deprecation.py:364] From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "2023-05-21 13:32:49.336330: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'cond/SparseToDense/ParseSingleExample/ParseExample/ParseExampleV2_1' with dtype int64 and shape [1]\n",
      "\t [[{{node cond/SparseToDense/ParseSingleExample/ParseExample/ParseExampleV2_1}}]]\n",
      "2023-05-21 13:32:49.336434: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'cond/SparseToDense/ParseSingleExample/ParseExample/ParseExampleV2_1' with dtype int64 and shape [1]\n",
      "\t [[{{node cond/SparseToDense/ParseSingleExample/ParseExample/ParseExampleV2_1}}]]\n",
      "2023-05-21 13:32:49.348884: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'cond_1/SparseToDense/ParseSingleExample/ParseExample/ParseExampleV2_1' with dtype int64 and shape [1]\n",
      "\t [[{{node cond_1/SparseToDense/ParseSingleExample/ParseExample/ParseExampleV2_1}}]]\n",
      "2023-05-21 13:32:49.348969: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'cond_1/SparseToDense/ParseSingleExample/ParseExample/ParseExampleV2_1' with dtype int64 and shape [1]\n",
      "\t [[{{node cond_1/SparseToDense/ParseSingleExample/ParseExample/ParseExampleV2_1}}]]\n",
      "WARNING:tensorflow:From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0521 13:32:53.548075 140565636405056 deprecation.py:364] From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0521 13:32:56.290169 140565636405056 deprecation.py:364] From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0521 13:32:58.619115 140565636405056 deprecation.py:364] From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/object_detection/builders/optimizer_builder.py:124: The name tf.keras.optimizers.SGD is deprecated. Please use tf.keras.optimizers.legacy.SGD instead.\n",
      "\n",
      "W0521 13:33:00.555018 140565636405056 module_wrapper.py:149] From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/object_detection/builders/optimizer_builder.py:124: The name tf.keras.optimizers.SGD is deprecated. Please use tf.keras.optimizers.legacy.SGD instead.\n",
      "\n",
      "2023-05-21 13:33:00.586098: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_28' with dtype resource\n",
      "\t [[{{node Placeholder/_28}}]]\n",
      "2023-05-21 13:33:00.586568: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_25' with dtype int64\n",
      "\t [[{{node Placeholder/_25}}]]\n",
      "2023-05-21 13:33:01.081920: W tensorflow/core/framework/dataset.cc:807] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-05-21 13:33:01.082441: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-21 13:33:01.200970: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): CANCELLED: GetNextFromShard was cancelled\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2023-05-21 13:33:01.202023: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): CANCELLED: GetNextFromShard was cancelled\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]] [type.googleapis.com/tensorflow.DerivedStatus='']\n",
      "/home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/keras/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n",
      "I0521 13:33:04.989390 140559498860288 api.py:459] feature_map_spatial_dims: [(20, 20), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0521 13:33:06.499705 140559498860288 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0521 13:33:06.499870 140559498860288 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0521 13:33:06.499957 140559498860288 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0521 13:33:06.500076 140559498860288 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0521 13:33:06.500252 140559498860288 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0521 13:33:06.500428 140559498860288 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "I0521 13:33:15.546972 140559498860288 api.py:459] feature_map_spatial_dims: [(20, 20), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
      "2023-05-21 13:33:24.106555: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_27' with dtype int64\n",
      "\t [[{{node Placeholder/_27}}]]\n",
      "2023-05-21 13:33:24.106997: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_27' with dtype int64\n",
      "\t [[{{node Placeholder/_27}}]]\n",
      "2023-05-21 13:33:24.590702: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "WARNING:tensorflow:From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0521 13:33:25.298741 140559373035264 deprecation.py:569] From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "I0521 13:33:26.281662 140559373035264 api.py:459] feature_map_spatial_dims: [(20, 20), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
      "I0521 13:33:34.265001 140559373035264 api.py:459] feature_map_spatial_dims: [(20, 20), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
      "I0521 13:33:42.169842 140559373035264 api.py:459] feature_map_spatial_dims: [(20, 20), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
      "I0521 13:33:50.223182 140559373035264 api.py:459] feature_map_spatial_dims: [(20, 20), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
      "INFO:tensorflow:Step 100 per-step time 3.446s\n",
      "I0521 13:39:09.621477 140565636405056 model_lib_v2.py:705] Step 100 per-step time 3.446s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.32407892,\n",
      " 'Loss/localization_loss': 0.1640202,\n",
      " 'Loss/regularization_loss': 0.086422406,\n",
      " 'Loss/total_loss': 0.57452154,\n",
      " 'learning_rate': 0.05833312}\n",
      "I0521 13:39:09.621678 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.32407892,\n",
      " 'Loss/localization_loss': 0.1640202,\n",
      " 'Loss/regularization_loss': 0.086422406,\n",
      " 'Loss/total_loss': 0.57452154,\n",
      " 'learning_rate': 0.05833312}\n",
      "INFO:tensorflow:Step 200 per-step time 3.016s\n",
      "I0521 13:44:11.191950 140565636405056 model_lib_v2.py:705] Step 200 per-step time 3.016s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.23082791,\n",
      " 'Loss/localization_loss': 0.1137863,\n",
      " 'Loss/regularization_loss': 0.086428456,\n",
      " 'Loss/total_loss': 0.43104267,\n",
      " 'learning_rate': 0.1}\n",
      "I0521 13:44:11.192166 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.23082791,\n",
      " 'Loss/localization_loss': 0.1137863,\n",
      " 'Loss/regularization_loss': 0.086428456,\n",
      " 'Loss/total_loss': 0.43104267,\n",
      " 'learning_rate': 0.1}\n",
      "INFO:tensorflow:Step 300 per-step time 3.165s\n",
      "I0521 13:49:27.684729 140565636405056 model_lib_v2.py:705] Step 300 per-step time 3.165s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.22519949,\n",
      " 'Loss/localization_loss': 0.08904013,\n",
      " 'Loss/regularization_loss': 0.08643613,\n",
      " 'Loss/total_loss': 0.40067574,\n",
      " 'learning_rate': 0.09989295}\n",
      "I0521 13:49:27.684971 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.22519949,\n",
      " 'Loss/localization_loss': 0.08904013,\n",
      " 'Loss/regularization_loss': 0.08643613,\n",
      " 'Loss/total_loss': 0.40067574,\n",
      " 'learning_rate': 0.09989295}\n",
      "INFO:tensorflow:Step 400 per-step time 3.035s\n",
      "I0521 13:54:31.169349 140565636405056 model_lib_v2.py:705] Step 400 per-step time 3.035s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.15385066,\n",
      " 'Loss/localization_loss': 0.076338895,\n",
      " 'Loss/regularization_loss': 0.086417,\n",
      " 'Loss/total_loss': 0.31660655,\n",
      " 'learning_rate': 0.09957224}\n",
      "I0521 13:54:31.169549 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.15385066,\n",
      " 'Loss/localization_loss': 0.076338895,\n",
      " 'Loss/regularization_loss': 0.086417,\n",
      " 'Loss/total_loss': 0.31660655,\n",
      " 'learning_rate': 0.09957224}\n",
      "INFO:tensorflow:Step 500 per-step time 2.833s\n",
      "I0521 13:59:14.472712 140565636405056 model_lib_v2.py:705] Step 500 per-step time 2.833s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16172747,\n",
      " 'Loss/localization_loss': 0.07883608,\n",
      " 'Loss/regularization_loss': 0.086397685,\n",
      " 'Loss/total_loss': 0.32696122,\n",
      " 'learning_rate': 0.099039264}\n",
      "I0521 13:59:14.472890 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.16172747,\n",
      " 'Loss/localization_loss': 0.07883608,\n",
      " 'Loss/regularization_loss': 0.086397685,\n",
      " 'Loss/total_loss': 0.32696122,\n",
      " 'learning_rate': 0.099039264}\n",
      "INFO:tensorflow:Step 600 per-step time 3.045s\n",
      "I0521 14:04:18.931443 140565636405056 model_lib_v2.py:705] Step 600 per-step time 3.045s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10446149,\n",
      " 'Loss/localization_loss': 0.03420008,\n",
      " 'Loss/regularization_loss': 0.08637484,\n",
      " 'Loss/total_loss': 0.22503641,\n",
      " 'learning_rate': 0.09829629}\n",
      "I0521 14:04:18.931644 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.10446149,\n",
      " 'Loss/localization_loss': 0.03420008,\n",
      " 'Loss/regularization_loss': 0.08637484,\n",
      " 'Loss/total_loss': 0.22503641,\n",
      " 'learning_rate': 0.09829629}\n",
      "INFO:tensorflow:Step 700 per-step time 3.140s\n",
      "I0521 14:09:32.920896 140565636405056 model_lib_v2.py:705] Step 700 per-step time 3.140s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.15079457,\n",
      " 'Loss/localization_loss': 0.056959454,\n",
      " 'Loss/regularization_loss': 0.08635307,\n",
      " 'Loss/total_loss': 0.29410708,\n",
      " 'learning_rate': 0.09734651}\n",
      "I0521 14:09:32.921100 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.15079457,\n",
      " 'Loss/localization_loss': 0.056959454,\n",
      " 'Loss/regularization_loss': 0.08635307,\n",
      " 'Loss/total_loss': 0.29410708,\n",
      " 'learning_rate': 0.09734651}\n",
      "INFO:tensorflow:Step 800 per-step time 3.078s\n",
      "I0521 14:14:40.767747 140565636405056 model_lib_v2.py:705] Step 800 per-step time 3.078s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12774436,\n",
      " 'Loss/localization_loss': 0.052490205,\n",
      " 'Loss/regularization_loss': 0.08632175,\n",
      " 'Loss/total_loss': 0.26655632,\n",
      " 'learning_rate': 0.09619398}\n",
      "I0521 14:14:40.767924 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.12774436,\n",
      " 'Loss/localization_loss': 0.052490205,\n",
      " 'Loss/regularization_loss': 0.08632175,\n",
      " 'Loss/total_loss': 0.26655632,\n",
      " 'learning_rate': 0.09619398}\n",
      "INFO:tensorflow:Step 900 per-step time 2.904s\n",
      "I0521 14:19:31.141100 140565636405056 model_lib_v2.py:705] Step 900 per-step time 2.904s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16136374,\n",
      " 'Loss/localization_loss': 0.05088186,\n",
      " 'Loss/regularization_loss': 0.08629133,\n",
      " 'Loss/total_loss': 0.29853693,\n",
      " 'learning_rate': 0.09484364}\n",
      "I0521 14:19:31.141307 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.16136374,\n",
      " 'Loss/localization_loss': 0.05088186,\n",
      " 'Loss/regularization_loss': 0.08629133,\n",
      " 'Loss/total_loss': 0.29853693,\n",
      " 'learning_rate': 0.09484364}\n",
      "INFO:tensorflow:Step 1000 per-step time 3.198s\n",
      "I0521 14:24:50.977008 140565636405056 model_lib_v2.py:705] Step 1000 per-step time 3.198s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11716381,\n",
      " 'Loss/localization_loss': 0.045418475,\n",
      " 'Loss/regularization_loss': 0.086266264,\n",
      " 'Loss/total_loss': 0.24884854,\n",
      " 'learning_rate': 0.093301274}\n",
      "I0521 14:24:50.977186 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.11716381,\n",
      " 'Loss/localization_loss': 0.045418475,\n",
      " 'Loss/regularization_loss': 0.086266264,\n",
      " 'Loss/total_loss': 0.24884854,\n",
      " 'learning_rate': 0.093301274}\n",
      "INFO:tensorflow:Step 1100 per-step time 3.219s\n",
      "I0521 14:30:12.906946 140565636405056 model_lib_v2.py:705] Step 1100 per-step time 3.219s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09126183,\n",
      " 'Loss/localization_loss': 0.03315998,\n",
      " 'Loss/regularization_loss': 0.08623262,\n",
      " 'Loss/total_loss': 0.21065442,\n",
      " 'learning_rate': 0.09157348}\n",
      "I0521 14:30:12.907133 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.09126183,\n",
      " 'Loss/localization_loss': 0.03315998,\n",
      " 'Loss/regularization_loss': 0.08623262,\n",
      " 'Loss/total_loss': 0.21065442,\n",
      " 'learning_rate': 0.09157348}\n",
      "INFO:tensorflow:Step 1200 per-step time 3.216s\n",
      "I0521 14:35:34.554143 140565636405056 model_lib_v2.py:705] Step 1200 per-step time 3.216s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.115296386,\n",
      " 'Loss/localization_loss': 0.04011263,\n",
      " 'Loss/regularization_loss': 0.08619773,\n",
      " 'Loss/total_loss': 0.24160674,\n",
      " 'learning_rate': 0.08966767}\n",
      "I0521 14:35:34.554337 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.115296386,\n",
      " 'Loss/localization_loss': 0.04011263,\n",
      " 'Loss/regularization_loss': 0.08619773,\n",
      " 'Loss/total_loss': 0.24160674,\n",
      " 'learning_rate': 0.08966767}\n",
      "INFO:tensorflow:Step 1300 per-step time 2.941s\n",
      "I0521 14:40:28.675574 140565636405056 model_lib_v2.py:705] Step 1300 per-step time 2.941s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.110376514,\n",
      " 'Loss/localization_loss': 0.027462317,\n",
      " 'Loss/regularization_loss': 0.08616341,\n",
      " 'Loss/total_loss': 0.22400224,\n",
      " 'learning_rate': 0.08759199}\n",
      "I0521 14:40:28.675749 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.110376514,\n",
      " 'Loss/localization_loss': 0.027462317,\n",
      " 'Loss/regularization_loss': 0.08616341,\n",
      " 'Loss/total_loss': 0.22400224,\n",
      " 'learning_rate': 0.08759199}\n",
      "INFO:tensorflow:Step 1400 per-step time 2.848s\n",
      "I0521 14:45:13.525325 140565636405056 model_lib_v2.py:705] Step 1400 per-step time 2.848s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14441411,\n",
      " 'Loss/localization_loss': 0.042909194,\n",
      " 'Loss/regularization_loss': 0.08613344,\n",
      " 'Loss/total_loss': 0.27345675,\n",
      " 'learning_rate': 0.08535534}\n",
      "I0521 14:45:13.525499 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.14441411,\n",
      " 'Loss/localization_loss': 0.042909194,\n",
      " 'Loss/regularization_loss': 0.08613344,\n",
      " 'Loss/total_loss': 0.27345675,\n",
      " 'learning_rate': 0.08535534}\n",
      "INFO:tensorflow:Step 1500 per-step time 2.852s\n",
      "I0521 14:49:58.682233 140565636405056 model_lib_v2.py:705] Step 1500 per-step time 2.852s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09891498,\n",
      " 'Loss/localization_loss': 0.033607997,\n",
      " 'Loss/regularization_loss': 0.08610087,\n",
      " 'Loss/total_loss': 0.21862385,\n",
      " 'learning_rate': 0.082967296}\n",
      "I0521 14:49:58.682400 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.09891498,\n",
      " 'Loss/localization_loss': 0.033607997,\n",
      " 'Loss/regularization_loss': 0.08610087,\n",
      " 'Loss/total_loss': 0.21862385,\n",
      " 'learning_rate': 0.082967296}\n",
      "INFO:tensorflow:Step 1600 per-step time 2.849s\n",
      "I0521 14:54:43.561831 140565636405056 model_lib_v2.py:705] Step 1600 per-step time 2.849s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.096828125,\n",
      " 'Loss/localization_loss': 0.02336081,\n",
      " 'Loss/regularization_loss': 0.08606928,\n",
      " 'Loss/total_loss': 0.20625821,\n",
      " 'learning_rate': 0.08043807}\n",
      "I0521 14:54:43.562003 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.096828125,\n",
      " 'Loss/localization_loss': 0.02336081,\n",
      " 'Loss/regularization_loss': 0.08606928,\n",
      " 'Loss/total_loss': 0.20625821,\n",
      " 'learning_rate': 0.08043807}\n",
      "INFO:tensorflow:Step 1700 per-step time 2.847s\n",
      "I0521 14:59:28.248771 140565636405056 model_lib_v2.py:705] Step 1700 per-step time 2.847s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13552175,\n",
      " 'Loss/localization_loss': 0.052127272,\n",
      " 'Loss/regularization_loss': 0.08603217,\n",
      " 'Loss/total_loss': 0.2736812,\n",
      " 'learning_rate': 0.07777851}\n",
      "I0521 14:59:28.248953 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.13552175,\n",
      " 'Loss/localization_loss': 0.052127272,\n",
      " 'Loss/regularization_loss': 0.08603217,\n",
      " 'Loss/total_loss': 0.2736812,\n",
      " 'learning_rate': 0.07777851}\n",
      "INFO:tensorflow:Step 1800 per-step time 2.920s\n",
      "I0521 15:04:20.247225 140565636405056 model_lib_v2.py:705] Step 1800 per-step time 2.920s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10850073,\n",
      " 'Loss/localization_loss': 0.029442122,\n",
      " 'Loss/regularization_loss': 0.08599815,\n",
      " 'Loss/total_loss': 0.223941,\n",
      " 'learning_rate': 0.075}\n",
      "I0521 15:04:20.247431 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.10850073,\n",
      " 'Loss/localization_loss': 0.029442122,\n",
      " 'Loss/regularization_loss': 0.08599815,\n",
      " 'Loss/total_loss': 0.223941,\n",
      " 'learning_rate': 0.075}\n",
      "INFO:tensorflow:Step 1900 per-step time 3.189s\n",
      "I0521 15:09:39.128891 140565636405056 model_lib_v2.py:705] Step 1900 per-step time 3.189s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13403235,\n",
      " 'Loss/localization_loss': 0.03629151,\n",
      " 'Loss/regularization_loss': 0.08596325,\n",
      " 'Loss/total_loss': 0.2562871,\n",
      " 'learning_rate': 0.07211443}\n",
      "I0521 15:09:39.129082 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.13403235,\n",
      " 'Loss/localization_loss': 0.03629151,\n",
      " 'Loss/regularization_loss': 0.08596325,\n",
      " 'Loss/total_loss': 0.2562871,\n",
      " 'learning_rate': 0.07211443}\n",
      "INFO:tensorflow:Step 2000 per-step time 3.194s\n",
      "I0521 15:14:58.542830 140565636405056 model_lib_v2.py:705] Step 2000 per-step time 3.194s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0902893,\n",
      " 'Loss/localization_loss': 0.024078544,\n",
      " 'Loss/regularization_loss': 0.08592699,\n",
      " 'Loss/total_loss': 0.20029482,\n",
      " 'learning_rate': 0.06913417}\n",
      "I0521 15:14:58.543031 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.0902893,\n",
      " 'Loss/localization_loss': 0.024078544,\n",
      " 'Loss/regularization_loss': 0.08592699,\n",
      " 'Loss/total_loss': 0.20029482,\n",
      " 'learning_rate': 0.06913417}\n",
      "INFO:tensorflow:Step 2100 per-step time 3.206s\n",
      "I0521 15:20:19.189279 140565636405056 model_lib_v2.py:705] Step 2100 per-step time 3.206s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12207386,\n",
      " 'Loss/localization_loss': 0.02734776,\n",
      " 'Loss/regularization_loss': 0.08589356,\n",
      " 'Loss/total_loss': 0.23531517,\n",
      " 'learning_rate': 0.06607197}\n",
      "I0521 15:20:19.189467 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.12207386,\n",
      " 'Loss/localization_loss': 0.02734776,\n",
      " 'Loss/regularization_loss': 0.08589356,\n",
      " 'Loss/total_loss': 0.23531517,\n",
      " 'learning_rate': 0.06607197}\n",
      "INFO:tensorflow:Step 2200 per-step time 2.847s\n",
      "I0521 15:25:03.913023 140565636405056 model_lib_v2.py:705] Step 2200 per-step time 2.847s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10486816,\n",
      " 'Loss/localization_loss': 0.027836328,\n",
      " 'Loss/regularization_loss': 0.085861765,\n",
      " 'Loss/total_loss': 0.21856625,\n",
      " 'learning_rate': 0.06294095}\n",
      "I0521 15:25:03.913196 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.10486816,\n",
      " 'Loss/localization_loss': 0.027836328,\n",
      " 'Loss/regularization_loss': 0.085861765,\n",
      " 'Loss/total_loss': 0.21856625,\n",
      " 'learning_rate': 0.06294095}\n",
      "INFO:tensorflow:Step 2300 per-step time 2.839s\n",
      "I0521 15:29:47.793897 140565636405056 model_lib_v2.py:705] Step 2300 per-step time 2.839s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11204711,\n",
      " 'Loss/localization_loss': 0.024433095,\n",
      " 'Loss/regularization_loss': 0.08583039,\n",
      " 'Loss/total_loss': 0.2223106,\n",
      " 'learning_rate': 0.059754517}\n",
      "I0521 15:29:47.794068 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.11204711,\n",
      " 'Loss/localization_loss': 0.024433095,\n",
      " 'Loss/regularization_loss': 0.08583039,\n",
      " 'Loss/total_loss': 0.2223106,\n",
      " 'learning_rate': 0.059754517}\n",
      "INFO:tensorflow:Step 2400 per-step time 2.839s\n",
      "I0521 15:34:31.704397 140565636405056 model_lib_v2.py:705] Step 2400 per-step time 2.839s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08630907,\n",
      " 'Loss/localization_loss': 0.031995405,\n",
      " 'Loss/regularization_loss': 0.085800745,\n",
      " 'Loss/total_loss': 0.20410521,\n",
      " 'learning_rate': 0.056526303}\n",
      "I0521 15:34:31.704584 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.08630907,\n",
      " 'Loss/localization_loss': 0.031995405,\n",
      " 'Loss/regularization_loss': 0.085800745,\n",
      " 'Loss/total_loss': 0.20410521,\n",
      " 'learning_rate': 0.056526303}\n",
      "INFO:tensorflow:Step 2500 per-step time 2.981s\n",
      "I0521 15:39:29.847611 140565636405056 model_lib_v2.py:705] Step 2500 per-step time 2.981s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1104614,\n",
      " 'Loss/localization_loss': 0.026250985,\n",
      " 'Loss/regularization_loss': 0.08576949,\n",
      " 'Loss/total_loss': 0.22248188,\n",
      " 'learning_rate': 0.05327016}\n",
      "I0521 15:39:29.847795 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.1104614,\n",
      " 'Loss/localization_loss': 0.026250985,\n",
      " 'Loss/regularization_loss': 0.08576949,\n",
      " 'Loss/total_loss': 0.22248188,\n",
      " 'learning_rate': 0.05327016}\n",
      "INFO:tensorflow:Step 2600 per-step time 3.067s\n",
      "I0521 15:44:36.521147 140565636405056 model_lib_v2.py:705] Step 2600 per-step time 3.067s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0902231,\n",
      " 'Loss/localization_loss': 0.026071701,\n",
      " 'Loss/regularization_loss': 0.085740305,\n",
      " 'Loss/total_loss': 0.2020351,\n",
      " 'learning_rate': 0.049999997}\n",
      "I0521 15:44:36.521322 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.0902231,\n",
      " 'Loss/localization_loss': 0.026071701,\n",
      " 'Loss/regularization_loss': 0.085740305,\n",
      " 'Loss/total_loss': 0.2020351,\n",
      " 'learning_rate': 0.049999997}\n",
      "INFO:tensorflow:Step 2700 per-step time 3.037s\n",
      "I0521 15:49:40.242916 140565636405056 model_lib_v2.py:705] Step 2700 per-step time 3.037s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10909939,\n",
      " 'Loss/localization_loss': 0.029077493,\n",
      " 'Loss/regularization_loss': 0.08571133,\n",
      " 'Loss/total_loss': 0.22388822,\n",
      " 'learning_rate': 0.046729844}\n",
      "I0521 15:49:40.243086 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.10909939,\n",
      " 'Loss/localization_loss': 0.029077493,\n",
      " 'Loss/regularization_loss': 0.08571133,\n",
      " 'Loss/total_loss': 0.22388822,\n",
      " 'learning_rate': 0.046729844}\n",
      "INFO:tensorflow:Step 2800 per-step time 3.064s\n",
      "I0521 15:54:46.654166 140565636405056 model_lib_v2.py:705] Step 2800 per-step time 3.064s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11408015,\n",
      " 'Loss/localization_loss': 0.027817199,\n",
      " 'Loss/regularization_loss': 0.08568391,\n",
      " 'Loss/total_loss': 0.22758128,\n",
      " 'learning_rate': 0.04347369}\n",
      "I0521 15:54:46.654343 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.11408015,\n",
      " 'Loss/localization_loss': 0.027817199,\n",
      " 'Loss/regularization_loss': 0.08568391,\n",
      " 'Loss/total_loss': 0.22758128,\n",
      " 'learning_rate': 0.04347369}\n",
      "INFO:tensorflow:Step 2900 per-step time 2.845s\n",
      "I0521 15:59:31.180713 140565636405056 model_lib_v2.py:705] Step 2900 per-step time 2.845s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16722631,\n",
      " 'Loss/localization_loss': 0.04942689,\n",
      " 'Loss/regularization_loss': 0.08565814,\n",
      " 'Loss/total_loss': 0.30231136,\n",
      " 'learning_rate': 0.04024548}\n",
      "I0521 15:59:31.180881 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.16722631,\n",
      " 'Loss/localization_loss': 0.04942689,\n",
      " 'Loss/regularization_loss': 0.08565814,\n",
      " 'Loss/total_loss': 0.30231136,\n",
      " 'learning_rate': 0.04024548}\n",
      "INFO:tensorflow:Step 3000 per-step time 3.027s\n",
      "I0521 16:04:33.900460 140565636405056 model_lib_v2.py:705] Step 3000 per-step time 3.027s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1160619,\n",
      " 'Loss/localization_loss': 0.024498697,\n",
      " 'Loss/regularization_loss': 0.08563312,\n",
      " 'Loss/total_loss': 0.22619373,\n",
      " 'learning_rate': 0.037059043}\n",
      "I0521 16:04:33.900637 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.1160619,\n",
      " 'Loss/localization_loss': 0.024498697,\n",
      " 'Loss/regularization_loss': 0.08563312,\n",
      " 'Loss/total_loss': 0.22619373,\n",
      " 'learning_rate': 0.037059043}\n",
      "INFO:tensorflow:Step 3100 per-step time 3.065s\n",
      "I0521 16:09:40.422286 140565636405056 model_lib_v2.py:705] Step 3100 per-step time 3.065s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09075609,\n",
      " 'Loss/localization_loss': 0.0316303,\n",
      " 'Loss/regularization_loss': 0.08561089,\n",
      " 'Loss/total_loss': 0.20799728,\n",
      " 'learning_rate': 0.03392802}\n",
      "I0521 16:09:40.422460 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.09075609,\n",
      " 'Loss/localization_loss': 0.0316303,\n",
      " 'Loss/regularization_loss': 0.08561089,\n",
      " 'Loss/total_loss': 0.20799728,\n",
      " 'learning_rate': 0.03392802}\n",
      "INFO:tensorflow:Step 3200 per-step time 2.840s\n",
      "I0521 16:14:24.376286 140565636405056 model_lib_v2.py:705] Step 3200 per-step time 2.840s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07332103,\n",
      " 'Loss/localization_loss': 0.018850587,\n",
      " 'Loss/regularization_loss': 0.08558968,\n",
      " 'Loss/total_loss': 0.17776129,\n",
      " 'learning_rate': 0.030865824}\n",
      "I0521 16:14:24.376457 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.07332103,\n",
      " 'Loss/localization_loss': 0.018850587,\n",
      " 'Loss/regularization_loss': 0.08558968,\n",
      " 'Loss/total_loss': 0.17776129,\n",
      " 'learning_rate': 0.030865824}\n",
      "INFO:tensorflow:Step 3300 per-step time 2.850s\n",
      "I0521 16:19:09.368903 140565636405056 model_lib_v2.py:705] Step 3300 per-step time 2.850s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13701406,\n",
      " 'Loss/localization_loss': 0.054825272,\n",
      " 'Loss/regularization_loss': 0.08557148,\n",
      " 'Loss/total_loss': 0.2774108,\n",
      " 'learning_rate': 0.02788557}\n",
      "I0521 16:19:09.369193 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.13701406,\n",
      " 'Loss/localization_loss': 0.054825272,\n",
      " 'Loss/regularization_loss': 0.08557148,\n",
      " 'Loss/total_loss': 0.2774108,\n",
      " 'learning_rate': 0.02788557}\n",
      "INFO:tensorflow:Step 3400 per-step time 3.191s\n",
      "I0521 16:24:28.448060 140565636405056 model_lib_v2.py:705] Step 3400 per-step time 3.191s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.073008575,\n",
      " 'Loss/localization_loss': 0.015605648,\n",
      " 'Loss/regularization_loss': 0.08555357,\n",
      " 'Loss/total_loss': 0.1741678,\n",
      " 'learning_rate': 0.024999997}\n",
      "I0521 16:24:28.448243 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.073008575,\n",
      " 'Loss/localization_loss': 0.015605648,\n",
      " 'Loss/regularization_loss': 0.08555357,\n",
      " 'Loss/total_loss': 0.1741678,\n",
      " 'learning_rate': 0.024999997}\n",
      "INFO:tensorflow:Step 3500 per-step time 3.206s\n",
      "I0521 16:29:49.075461 140565636405056 model_lib_v2.py:705] Step 3500 per-step time 3.206s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07686885,\n",
      " 'Loss/localization_loss': 0.018493682,\n",
      " 'Loss/regularization_loss': 0.0855376,\n",
      " 'Loss/total_loss': 0.18090013,\n",
      " 'learning_rate': 0.02222149}\n",
      "I0521 16:29:49.075674 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.07686885,\n",
      " 'Loss/localization_loss': 0.018493682,\n",
      " 'Loss/regularization_loss': 0.0855376,\n",
      " 'Loss/total_loss': 0.18090013,\n",
      " 'learning_rate': 0.02222149}\n",
      "INFO:tensorflow:Step 3600 per-step time 3.012s\n",
      "I0521 16:34:50.237775 140565636405056 model_lib_v2.py:705] Step 3600 per-step time 3.012s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.085124314,\n",
      " 'Loss/localization_loss': 0.020741498,\n",
      " 'Loss/regularization_loss': 0.08552301,\n",
      " 'Loss/total_loss': 0.19138882,\n",
      " 'learning_rate': 0.01956193}\n",
      "I0521 16:34:50.237966 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.085124314,\n",
      " 'Loss/localization_loss': 0.020741498,\n",
      " 'Loss/regularization_loss': 0.08552301,\n",
      " 'Loss/total_loss': 0.19138882,\n",
      " 'learning_rate': 0.01956193}\n",
      "INFO:tensorflow:Step 3700 per-step time 3.215s\n",
      "I0521 16:40:11.774495 140565636405056 model_lib_v2.py:705] Step 3700 per-step time 3.215s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07983397,\n",
      " 'Loss/localization_loss': 0.02689068,\n",
      " 'Loss/regularization_loss': 0.08551061,\n",
      " 'Loss/total_loss': 0.19223526,\n",
      " 'learning_rate': 0.017032713}\n",
      "I0521 16:40:11.774810 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.07983397,\n",
      " 'Loss/localization_loss': 0.02689068,\n",
      " 'Loss/regularization_loss': 0.08551061,\n",
      " 'Loss/total_loss': 0.19223526,\n",
      " 'learning_rate': 0.017032713}\n",
      "INFO:tensorflow:Step 3800 per-step time 3.069s\n",
      "I0521 16:45:18.710200 140565636405056 model_lib_v2.py:705] Step 3800 per-step time 3.069s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11548862,\n",
      " 'Loss/localization_loss': 0.02538835,\n",
      " 'Loss/regularization_loss': 0.08549969,\n",
      " 'Loss/total_loss': 0.22637665,\n",
      " 'learning_rate': 0.014644662}\n",
      "I0521 16:45:18.710390 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.11548862,\n",
      " 'Loss/localization_loss': 0.02538835,\n",
      " 'Loss/regularization_loss': 0.08549969,\n",
      " 'Loss/total_loss': 0.22637665,\n",
      " 'learning_rate': 0.014644662}\n",
      "INFO:tensorflow:Step 3900 per-step time 2.863s\n",
      "I0521 16:50:04.968240 140565636405056 model_lib_v2.py:705] Step 3900 per-step time 2.863s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.110175475,\n",
      " 'Loss/localization_loss': 0.038673967,\n",
      " 'Loss/regularization_loss': 0.08548973,\n",
      " 'Loss/total_loss': 0.23433918,\n",
      " 'learning_rate': 0.012408006}\n",
      "I0521 16:50:04.968437 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.110175475,\n",
      " 'Loss/localization_loss': 0.038673967,\n",
      " 'Loss/regularization_loss': 0.08548973,\n",
      " 'Loss/total_loss': 0.23433918,\n",
      " 'learning_rate': 0.012408006}\n",
      "INFO:tensorflow:Step 4000 per-step time 3.208s\n",
      "I0521 16:55:25.814427 140565636405056 model_lib_v2.py:705] Step 4000 per-step time 3.208s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08252094,\n",
      " 'Loss/localization_loss': 0.025452405,\n",
      " 'Loss/regularization_loss': 0.08548142,\n",
      " 'Loss/total_loss': 0.19345477,\n",
      " 'learning_rate': 0.0103323255}\n",
      "I0521 16:55:25.814624 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.08252094,\n",
      " 'Loss/localization_loss': 0.025452405,\n",
      " 'Loss/regularization_loss': 0.08548142,\n",
      " 'Loss/total_loss': 0.19345477,\n",
      " 'learning_rate': 0.0103323255}\n",
      "INFO:tensorflow:Step 4100 per-step time 3.213s\n",
      "I0521 17:00:47.157683 140565636405056 model_lib_v2.py:705] Step 4100 per-step time 3.213s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12523672,\n",
      " 'Loss/localization_loss': 0.028295977,\n",
      " 'Loss/regularization_loss': 0.08547487,\n",
      " 'Loss/total_loss': 0.23900756,\n",
      " 'learning_rate': 0.008426517}\n",
      "I0521 17:00:47.157869 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.12523672,\n",
      " 'Loss/localization_loss': 0.028295977,\n",
      " 'Loss/regularization_loss': 0.08547487,\n",
      " 'Loss/total_loss': 0.23900756,\n",
      " 'learning_rate': 0.008426517}\n",
      "INFO:tensorflow:Step 4200 per-step time 3.208s\n",
      "I0521 17:06:07.927371 140565636405056 model_lib_v2.py:705] Step 4200 per-step time 3.208s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.068004176,\n",
      " 'Loss/localization_loss': 0.015766347,\n",
      " 'Loss/regularization_loss': 0.0854693,\n",
      " 'Loss/total_loss': 0.16923982,\n",
      " 'learning_rate': 0.006698725}\n",
      "I0521 17:06:07.927544 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.068004176,\n",
      " 'Loss/localization_loss': 0.015766347,\n",
      " 'Loss/regularization_loss': 0.0854693,\n",
      " 'Loss/total_loss': 0.16923982,\n",
      " 'learning_rate': 0.006698725}\n",
      "INFO:tensorflow:Step 4300 per-step time 3.020s\n",
      "I0521 17:11:09.957418 140565636405056 model_lib_v2.py:705] Step 4300 per-step time 3.020s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08558134,\n",
      " 'Loss/localization_loss': 0.014314994,\n",
      " 'Loss/regularization_loss': 0.08546529,\n",
      " 'Loss/total_loss': 0.18536162,\n",
      " 'learning_rate': 0.005156362}\n",
      "I0521 17:11:09.957602 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.08558134,\n",
      " 'Loss/localization_loss': 0.014314994,\n",
      " 'Loss/regularization_loss': 0.08546529,\n",
      " 'Loss/total_loss': 0.18536162,\n",
      " 'learning_rate': 0.005156362}\n",
      "INFO:tensorflow:Step 4400 per-step time 3.109s\n",
      "I0521 17:16:20.890924 140565636405056 model_lib_v2.py:705] Step 4400 per-step time 3.109s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.06001362,\n",
      " 'Loss/localization_loss': 0.013679377,\n",
      " 'Loss/regularization_loss': 0.085462034,\n",
      " 'Loss/total_loss': 0.15915503,\n",
      " 'learning_rate': 0.003806019}\n",
      "I0521 17:16:20.891113 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.06001362,\n",
      " 'Loss/localization_loss': 0.013679377,\n",
      " 'Loss/regularization_loss': 0.085462034,\n",
      " 'Loss/total_loss': 0.15915503,\n",
      " 'learning_rate': 0.003806019}\n",
      "INFO:tensorflow:Step 4500 per-step time 2.929s\n",
      "I0521 17:21:13.791408 140565636405056 model_lib_v2.py:705] Step 4500 per-step time 2.929s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10126096,\n",
      " 'Loss/localization_loss': 0.041388776,\n",
      " 'Loss/regularization_loss': 0.08545958,\n",
      " 'Loss/total_loss': 0.22810932,\n",
      " 'learning_rate': 0.0026534915}\n",
      "I0521 17:21:13.791590 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.10126096,\n",
      " 'Loss/localization_loss': 0.041388776,\n",
      " 'Loss/regularization_loss': 0.08545958,\n",
      " 'Loss/total_loss': 0.22810932,\n",
      " 'learning_rate': 0.0026534915}\n",
      "INFO:tensorflow:Step 4600 per-step time 3.134s\n",
      "I0521 17:26:27.189407 140565636405056 model_lib_v2.py:705] Step 4600 per-step time 3.134s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.082881674,\n",
      " 'Loss/localization_loss': 0.019030023,\n",
      " 'Loss/regularization_loss': 0.08545802,\n",
      " 'Loss/total_loss': 0.18736972,\n",
      " 'learning_rate': 0.0017037065}\n",
      "I0521 17:26:27.189589 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.082881674,\n",
      " 'Loss/localization_loss': 0.019030023,\n",
      " 'Loss/regularization_loss': 0.08545802,\n",
      " 'Loss/total_loss': 0.18736972,\n",
      " 'learning_rate': 0.0017037065}\n",
      "INFO:tensorflow:Step 4700 per-step time 3.176s\n",
      "I0521 17:31:44.755186 140565636405056 model_lib_v2.py:705] Step 4700 per-step time 3.176s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.050870568,\n",
      " 'Loss/localization_loss': 0.022620667,\n",
      " 'Loss/regularization_loss': 0.08545704,\n",
      " 'Loss/total_loss': 0.15894827,\n",
      " 'learning_rate': 0.0009607345}\n",
      "I0521 17:31:44.755399 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.050870568,\n",
      " 'Loss/localization_loss': 0.022620667,\n",
      " 'Loss/regularization_loss': 0.08545704,\n",
      " 'Loss/total_loss': 0.15894827,\n",
      " 'learning_rate': 0.0009607345}\n",
      "INFO:tensorflow:Step 4800 per-step time 3.174s\n",
      "I0521 17:37:02.131305 140565636405056 model_lib_v2.py:705] Step 4800 per-step time 3.174s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.090638384,\n",
      " 'Loss/localization_loss': 0.017331704,\n",
      " 'Loss/regularization_loss': 0.085456505,\n",
      " 'Loss/total_loss': 0.1934266,\n",
      " 'learning_rate': 0.0004277587}\n",
      "I0521 17:37:02.131488 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.090638384,\n",
      " 'Loss/localization_loss': 0.017331704,\n",
      " 'Loss/regularization_loss': 0.085456505,\n",
      " 'Loss/total_loss': 0.1934266,\n",
      " 'learning_rate': 0.0004277587}\n",
      "INFO:tensorflow:Step 4900 per-step time 3.180s\n",
      "I0521 17:42:20.107452 140565636405056 model_lib_v2.py:705] Step 4900 per-step time 3.180s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07354693,\n",
      " 'Loss/localization_loss': 0.01803455,\n",
      " 'Loss/regularization_loss': 0.085456304,\n",
      " 'Loss/total_loss': 0.17703778,\n",
      " 'learning_rate': 0.000107052925}\n",
      "I0521 17:42:20.107631 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.07354693,\n",
      " 'Loss/localization_loss': 0.01803455,\n",
      " 'Loss/regularization_loss': 0.085456304,\n",
      " 'Loss/total_loss': 0.17703778,\n",
      " 'learning_rate': 0.000107052925}\n",
      "INFO:tensorflow:Step 5000 per-step time 3.180s\n",
      "I0521 17:47:38.103747 140565636405056 model_lib_v2.py:705] Step 5000 per-step time 3.180s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.05882495,\n",
      " 'Loss/localization_loss': 0.011864563,\n",
      " 'Loss/regularization_loss': 0.08545628,\n",
      " 'Loss/total_loss': 0.1561458,\n",
      " 'learning_rate': 0.0}\n",
      "I0521 17:47:38.103947 140565636405056 model_lib_v2.py:708] {'Loss/classification_loss': 0.05882495,\n",
      " 'Loss/localization_loss': 0.011864563,\n",
      " 'Loss/regularization_loss': 0.08545628,\n",
      " 'Loss/total_loss': 0.1561458,\n",
      " 'learning_rate': 0.0}\n"
     ]
    }
   ],
   "source": [
    "!python model_main_tf2.py --model_dir=output/ --pipeline_config_path=ssd_mobilenet_v2_ft/pipeline.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-20 10:11:40.953422: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "2023-05-20 10:11:42.520505: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:tensorflow:From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "W0520 10:11:42.681027 140228047935296 deprecation.py:641] From /home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "I0520 10:11:45.313997 140228047935296 api.py:459] feature_map_spatial_dims: [(20, 20), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0520 10:11:46.850635 140228047935296 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0520 10:11:46.850815 140228047935296 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0520 10:11:46.850901 140228047935296 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0520 10:11:46.850981 140228047935296 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0520 10:11:46.851059 140228047935296 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0520 10:11:46.851135 140228047935296 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "I0520 10:11:52.100094 140228047935296 api.py:459] feature_map_spatial_dims: [(20, 20), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/irizqy/ml_ws/bangkit-ws/src/exporter_main_v2.py\", line 164, in <module>\n",
      "    app.run(main)\n",
      "  File \"/home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/absl/app.py\", line 308, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/absl/app.py\", line 254, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"/home/irizqy/ml_ws/bangkit-ws/src/exporter_main_v2.py\", line 157, in main\n",
      "    exporter_lib_v2.export_inference_graph(\n",
      "  File \"/home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/object_detection/exporter_lib_v2.py\", line 271, in export_inference_graph\n",
      "    status.assert_existing_objects_matched()\n",
      "  File \"/home/irizqy/ml_ws/bangkit-ws/lib/python3.9/site-packages/tensorflow/python/checkpoint/checkpoint.py\", line 955, in assert_existing_objects_matched\n",
      "    raise AssertionError(\n",
      "AssertionError: No checkpoint specified (save_path=None); nothing is being restored.\n"
     ]
    }
   ],
   "source": [
    "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path ssd_mobilenet_v2/pipeline.config --trained_checkpoint_dir src/output/ --output_directory src/ssd_mobilenet_v2_ft2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_MODEL_DIR = 'ssd_mobilenet_v2_ft/'\n",
    "PATH_TO_LABELS = '/home/irizqy/ml_ws/bangkit-ws/data/label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 17:52:07.477413: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-21 17:52:07.478249: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 8.235520839691162 seconds\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"saved_model\"\n",
    "\n",
    "print('Loading model...', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# Load saved model and build the detection function\n",
    "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                    use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATHS = ['/home/irizqy/ml_ws/bangkit-ws/data/bizit-dev_test-data/36_20230510_162147.jpg',\n",
    "               '/home/irizqy/ml_ws/bangkit-ws/data/bizit-dev_test-data/12_IMG20230504165724.jpg',\n",
    "               '/home/irizqy/ml_ws/bangkit-ws/data/bizit-dev_test-data/20_20230510_161931.jpg',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference for /home/irizqy/ml_ws/bangkit-ws/data/bizit-dev_test-data/36_20230510_162147.jpg... defaultdict(<class 'str'>, {(0.2317146360874176, 0.3359919786453247, 0.3352116644382477, 0.7213940620422363): 'Aqua'})\n",
      "Done\n",
      "Running inference for /home/irizqy/ml_ws/bangkit-ws/data/bizit-dev_test-data/12_IMG20230504165724.jpg... defaultdict(<class 'str'>, {(0.27207693457603455, 0.11005356907844543, 0.37995490431785583, 0.911182165145874): 'Aqua', (0.26456883549690247, 0.11640459299087524, 0.35175302624702454, 0.6515470147132874): 'Aqua'})\n",
      "Done\n",
      "Running inference for /home/irizqy/ml_ws/bangkit-ws/data/bizit-dev_test-data/20_20230510_161931.jpg... defaultdict(<class 'str'>, {})\n",
      "Done\n",
      "Running inference for /home/irizqy/ml_ws/bangkit-ws/data/bizit-dev_test-data/40_20230507_094336.jpg... defaultdict(<class 'str'>, {(0.3223600387573242, 0.425650954246521, 0.431532084941864, 0.828102707862854): 'Aqua'})\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
    "count = 0\n",
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "    \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "    Puts image into numpy array to feed into tensorflow graph.\n",
    "    Note that by convention we put it into a numpy array with shape\n",
    "    (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "    Args:\n",
    "      path: the file path to the image\n",
    "\n",
    "    Returns:\n",
    "      uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    \"\"\"\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "\n",
    "for image_path in IMAGE_PATHS:\n",
    "\n",
    "    print('Running inference for {}... '.format(image_path), end='')\n",
    "\n",
    "    image_np = load_image_into_numpy_array(image_path)\n",
    "    \n",
    "    if image_np.shape[2] == 4:\n",
    "        image_np = image_np[:, :, :3]\n",
    "\n",
    "    # Things to try:\n",
    "    # Flip horizontally\n",
    "    # image_np = np.fliplr(image_np).copy()\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    # image_np = np.tile(\n",
    "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
    "\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image_np)\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    # input_tensor = np.expand_dims(image_np, 0)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    # print(detections)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                   for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np_with_detections,\n",
    "          detections['detection_boxes'],\n",
    "          detections['detection_classes'],\n",
    "          detections['detection_scores'],\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=200,\n",
    "          min_score_thresh=.30,\n",
    "          agnostic_mode=False)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(image_np_with_detections)\n",
    "    im = Image.fromarray(image_np_with_detections)\n",
    "    im.save(f\"detected-logo2{count}.jpeg\")\n",
    "    count+=1\n",
    "    print('Done')\n",
    "    plt.show()\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('detection_anchor_indices', array([1467.,  447.,  490.,  508.,  880.,  514.,  577.,  448.,  880.,\n",
       "        362.,  444.,  507.,  451.,  583.,  579.,  876.,  459.,  519.,\n",
       "        520.,  494.,  568.,  582.,  879.,  504., 1841.,  564., 1935.,\n",
       "        885., 1869.,  564., 1975.,  819.,  522.,  882.,  585.,  360.,\n",
       "       2019.,  420.,  567.,  639.,  462.,  556.,  642., 2005.,  489.,\n",
       "       1767., 2025.,  492., 1972., 1993.,  816.,  879., 2028.,  822.,\n",
       "        414., 1131., 1134.,  561., 1467.,  585.,  821.,  540., 1905.,\n",
       "        480.,  460.,  474., 1957.,  362.,  856., 2013., 1862.,  490.,\n",
       "       2016., 1132., 1444., 1076., 1074.,  495.,  852., 1131.,  825.,\n",
       "        240., 1630., 1839.,  305., 1134., 1477.,  819.,  576.,  882.,\n",
       "       1132., 2031., 2006., 2033.,  243.,  789.,  549., 2011., 1959.,\n",
       "        861.], dtype=float32)), ('detection_multiclass_scores', array([[0.00931161, 0.04947763, 0.6265359 ],\n",
       "       [0.00674042, 0.02613527, 0.2936889 ],\n",
       "       [0.00840167, 0.25192142, 0.04423787],\n",
       "       [0.00960865, 0.020428  , 0.20616718],\n",
       "       [0.00969198, 0.1913204 , 0.11828656],\n",
       "       [0.00851865, 0.02034637, 0.1604332 ],\n",
       "       [0.00928079, 0.01923167, 0.15446723],\n",
       "       [0.00898433, 0.00642618, 0.1415486 ],\n",
       "       [0.00969198, 0.1913204 , 0.11828656],\n",
       "       [0.00766914, 0.11814877, 0.04629985],\n",
       "       [0.00770571, 0.01941678, 0.11476233],\n",
       "       [0.0071163 , 0.01741648, 0.10969766],\n",
       "       [0.00858508, 0.00986635, 0.10653726],\n",
       "       [0.00974771, 0.0215998 , 0.10159062],\n",
       "       [0.00661872, 0.02314659, 0.10148551],\n",
       "       [0.00706204, 0.10002045, 0.02884119],\n",
       "       [0.00636365, 0.0149252 , 0.09817052],\n",
       "       [0.00590549, 0.01533161, 0.09612558],\n",
       "       [0.0092199 , 0.01514187, 0.08976604],\n",
       "       [0.007873  , 0.08621871, 0.02069674],\n",
       "       [0.0099286 , 0.02014701, 0.08558987],\n",
       "       [0.00637574, 0.02911349, 0.08371657],\n",
       "       [0.00694864, 0.07918405, 0.05340268],\n",
       "       [0.00725714, 0.02605479, 0.07910606],\n",
       "       [0.01071407, 0.03557742, 0.07809765],\n",
       "       [0.00833425, 0.06840644, 0.07481884],\n",
       "       [0.00994546, 0.02758215, 0.07269859],\n",
       "       [0.00728921, 0.07236733, 0.01825849],\n",
       "       [0.01015419, 0.02563558, 0.06893085],\n",
       "       [0.00833425, 0.06840644, 0.07481884],\n",
       "       [0.00778401, 0.01993462, 0.06541801],\n",
       "       [0.00958392, 0.06522028, 0.03996786],\n",
       "       [0.00610084, 0.01897113, 0.06448074],\n",
       "       [0.00713176, 0.06255225, 0.03959007],\n",
       "       [0.00711195, 0.06064721, 0.04926931],\n",
       "       [0.00731868, 0.02493076, 0.06016961],\n",
       "       [0.00988483, 0.02113682, 0.0589124 ],\n",
       "       [0.00701648, 0.02921396, 0.05887241],\n",
       "       [0.00844591, 0.02643661, 0.05814015],\n",
       "       [0.00692369, 0.01174609, 0.05805825],\n",
       "       [0.00737867, 0.01851135, 0.05760692],\n",
       "       [0.00906031, 0.05748772, 0.01266069],\n",
       "       [0.00656877, 0.01482017, 0.05686764],\n",
       "       [0.00637716, 0.05662618, 0.05891507],\n",
       "       [0.00720509, 0.0558113 , 0.0242144 ],\n",
       "       [0.00840321, 0.01313664, 0.05553381],\n",
       "       [0.00913727, 0.02302987, 0.05534597],\n",
       "       [0.00844448, 0.05525217, 0.03438069],\n",
       "       [0.00967783, 0.05508547, 0.03401895],\n",
       "       [0.01058834, 0.01417277, 0.05473169],\n",
       "       [0.00959503, 0.05413409, 0.01610967],\n",
       "       [0.00694864, 0.07918405, 0.05340268],\n",
       "       [0.00959771, 0.03822517, 0.0518377 ],\n",
       "       [0.00911431, 0.05176795, 0.03186488],\n",
       "       [0.00632229, 0.05145653, 0.01926174],\n",
       "       [0.0073059 , 0.04181118, 0.05106933],\n",
       "       [0.00677686, 0.04057616, 0.04986162],\n",
       "       [0.00780379, 0.04964989, 0.02733159],\n",
       "       [0.00931161, 0.04947763, 0.6265359 ],\n",
       "       [0.00711195, 0.06064721, 0.04926931],\n",
       "       [0.00729323, 0.04923582, 0.0230035 ],\n",
       "       [0.00778272, 0.02072386, 0.04903493],\n",
       "       [0.01030209, 0.02510234, 0.04901714],\n",
       "       [0.00706156, 0.02060451, 0.04875199],\n",
       "       [0.00852342, 0.00976336, 0.04811119],\n",
       "       [0.00599563, 0.04791829, 0.03335522],\n",
       "       [0.01025309, 0.03832148, 0.04774244],\n",
       "       [0.00766914, 0.11814877, 0.04629985],\n",
       "       [0.00910495, 0.0060432 , 0.04615541],\n",
       "       [0.00936425, 0.0367602 , 0.04517397],\n",
       "       [0.00958514, 0.0450548 , 0.02211594],\n",
       "       [0.00840167, 0.25192142, 0.04423787],\n",
       "       [0.00898479, 0.02965419, 0.04401225],\n",
       "       [0.00966034, 0.03921774, 0.04387463],\n",
       "       [0.01091957, 0.04285467, 0.0158542 ],\n",
       "       [0.00717369, 0.04208816, 0.01380996],\n",
       "       [0.00717048, 0.03296749, 0.04197977],\n",
       "       [0.00687038, 0.04187399, 0.00928914],\n",
       "       [0.00698839, 0.00934486, 0.04184787],\n",
       "       [0.0073059 , 0.04181118, 0.05106933],\n",
       "       [0.00808803, 0.04117427, 0.02171682],\n",
       "       [0.0080379 , 0.029047  , 0.04101822],\n",
       "       [0.00920113, 0.04093224, 0.02323152],\n",
       "       [0.01120505, 0.02539823, 0.04084128],\n",
       "       [0.00650535, 0.04066459, 0.01576624],\n",
       "       [0.00677686, 0.04057616, 0.04986162],\n",
       "       [0.0112682 , 0.02598056, 0.04019975],\n",
       "       [0.00958392, 0.06522028, 0.03996786],\n",
       "       [0.00746904, 0.01609666, 0.03985156],\n",
       "       [0.00713176, 0.06255225, 0.03959007],\n",
       "       [0.00966034, 0.03921774, 0.04387463],\n",
       "       [0.00900774, 0.01679951, 0.03915095],\n",
       "       [0.00902227, 0.03024884, 0.03902882],\n",
       "       [0.00886974, 0.03899072, 0.04408803],\n",
       "       [0.00815184, 0.03889859, 0.02412785],\n",
       "       [0.00658212, 0.02591052, 0.0388864 ],\n",
       "       [0.00721657, 0.03884435, 0.02361779],\n",
       "       [0.00957898, 0.03881   , 0.03650726],\n",
       "       [0.00933214, 0.03880091, 0.033646  ],\n",
       "       [0.00570914, 0.00681336, 0.03863315]], dtype=float32)), ('raw_detection_boxes', array([[-1.35866832e-02, -2.19144486e-02,  5.05693778e-02,\n",
       "         9.37090218e-02],\n",
       "       [-2.03412324e-02, -1.28012434e-01,  6.96231425e-02,\n",
       "         2.14010611e-01],\n",
       "       [-9.70036834e-02, -4.78319116e-02,  1.77387848e-01,\n",
       "         9.94792283e-02],\n",
       "       [-7.17650913e-03,  2.37109661e-02,  5.33042178e-02,\n",
       "         1.49686620e-01],\n",
       "       [-1.19386930e-02, -7.25876838e-02,  7.28321150e-02,\n",
       "         2.57805884e-01],\n",
       "       [-9.71621275e-02, -1.09256059e-03,  1.64940596e-01,\n",
       "         1.50463849e-01],\n",
       "       [-4.18267585e-03,  7.21407011e-02,  5.04051298e-02,\n",
       "         2.07781762e-01],\n",
       "       [-7.77537562e-03, -3.29137295e-02,  6.93380684e-02,\n",
       "         3.22956562e-01],\n",
       "       [-9.75220650e-02,  4.36131880e-02,  1.59472153e-01,\n",
       "         2.02804714e-01],\n",
       "       [-1.54917687e-03,  1.22843459e-01,  5.27856536e-02,\n",
       "         2.57228315e-01],\n",
       "       [-8.06266814e-03, -4.12435830e-03,  7.09299222e-02,\n",
       "         3.86118114e-01],\n",
       "       [-9.74970311e-02,  9.14525613e-02,  1.56173870e-01,\n",
       "         2.55841583e-01],\n",
       "       [-2.26286612e-03,  1.74447477e-01,  5.16596735e-02,\n",
       "         3.04492474e-01],\n",
       "       [-1.24983266e-02,  2.38638073e-02,  7.03084618e-02,\n",
       "         4.37882960e-01],\n",
       "       [-9.82812047e-02,  1.38717741e-01,  1.61025614e-01,\n",
       "         3.08333486e-01],\n",
       "       [-3.05905193e-03,  2.24627733e-01,  5.31759895e-02,\n",
       "         3.52372348e-01],\n",
       "       [-1.66875869e-02,  7.79133141e-02,  7.17174709e-02,\n",
       "         4.88427669e-01],\n",
       "       [-1.03304431e-01,  1.88752294e-01,  1.63144603e-01,\n",
       "         3.59695256e-01],\n",
       "       [-3.73525731e-03,  2.74974138e-01,  5.36892712e-02,\n",
       "         4.01453465e-01],\n",
       "       [-1.72286816e-02,  1.30434319e-01,  7.17925876e-02,\n",
       "         5.42120934e-01],\n",
       "       [-1.04164042e-01,  2.38880709e-01,  1.64262086e-01,\n",
       "         4.09173131e-01],\n",
       "       [-4.16323170e-03,  3.24486911e-01,  5.35622276e-02,\n",
       "         4.51802492e-01],\n",
       "       [-1.68768428e-02,  1.85357288e-01,  7.21796304e-02,\n",
       "         5.87365866e-01],\n",
       "       [-1.04477204e-01,  2.89252371e-01,  1.61540687e-01,\n",
       "         4.59652513e-01],\n",
       "       [-4.83336858e-03,  3.74452412e-01,  5.41607514e-02,\n",
       "         5.00471294e-01],\n",
       "       [-1.73175745e-02,  2.38284171e-01,  7.33048469e-02,\n",
       "         6.31675720e-01],\n",
       "       [-1.05970651e-01,  3.39709669e-01,  1.57544225e-01,\n",
       "         5.08882642e-01],\n",
       "       [-4.73138690e-03,  4.25236046e-01,  5.52993901e-02,\n",
       "         5.48258662e-01],\n",
       "       [-1.85540132e-02,  2.86911815e-01,  7.33737350e-02,\n",
       "         6.83672190e-01],\n",
       "       [-1.07454143e-01,  3.90367657e-01,  1.58306330e-01,\n",
       "         5.57907999e-01],\n",
       "       [-5.06469235e-03,  4.75663900e-01,  5.48708141e-02,\n",
       "         5.98556280e-01],\n",
       "       [-1.91166885e-02,  3.37380707e-01,  7.20061362e-02,\n",
       "         7.37026989e-01],\n",
       "       [-1.07358336e-01,  4.41125721e-01,  1.61885709e-01,\n",
       "         6.09003305e-01],\n",
       "       [-4.91682254e-03,  5.25076032e-01,  5.40595725e-02,\n",
       "         6.50838852e-01],\n",
       "       [-1.78212225e-02,  3.86478424e-01,  7.09261298e-02,\n",
       "         7.90984273e-01],\n",
       "       [-1.05987288e-01,  4.90364134e-01,  1.64168358e-01,\n",
       "         6.59898698e-01],\n",
       "       [-4.97932918e-03,  5.74442863e-01,  5.34878150e-02,\n",
       "         7.01227546e-01],\n",
       "       [-1.73296612e-02,  4.36994851e-01,  7.10273832e-02,\n",
       "         8.40016067e-01],\n",
       "       [-1.05078995e-01,  5.39480269e-01,  1.64977431e-01,\n",
       "         7.09817827e-01],\n",
       "       [-4.10305336e-03,  6.24526143e-01,  5.34072816e-02,\n",
       "         7.52134085e-01],\n",
       "       [-1.65720154e-02,  4.85057086e-01,  7.15486035e-02,\n",
       "         8.97903681e-01],\n",
       "       [-1.04401469e-01,  5.87962151e-01,  1.64561152e-01,\n",
       "         7.59884477e-01],\n",
       "       [-3.35949846e-03,  6.74331069e-01,  5.33940047e-02,\n",
       "         8.02599192e-01],\n",
       "       [-1.65463910e-02,  5.32079637e-01,  7.28701949e-02,\n",
       "         9.51465070e-01],\n",
       "       [-1.04004979e-01,  6.37394845e-01,  1.63369298e-01,\n",
       "         8.11344564e-01],\n",
       "       [-2.49539316e-03,  7.23092854e-01,  5.19330129e-02,\n",
       "         8.54131401e-01],\n",
       "       [-1.36491098e-02,  5.80576777e-01,  7.27532059e-02,\n",
       "         9.95567203e-01],\n",
       "       [-1.02737978e-01,  6.85890973e-01,  1.62808493e-01,\n",
       "         8.60958517e-01],\n",
       "       [-2.81238742e-03,  7.71352589e-01,  4.95987833e-02,\n",
       "         9.06676233e-01],\n",
       "       [-1.10063981e-02,  6.33859515e-01,  7.07596764e-02,\n",
       "         1.03157222e+00],\n",
       "       [-9.91875529e-02,  7.35534370e-01,  1.62501782e-01,\n",
       "         9.10077155e-01],\n",
       "       [-6.48752786e-03,  8.21817696e-01,  4.97847274e-02,\n",
       "         9.53668058e-01],\n",
       "       [-1.42379291e-02,  6.93171322e-01,  7.25071132e-02,\n",
       "         1.05737722e+00],\n",
       "       [-1.00340977e-01,  7.88862228e-01,  1.59196302e-01,\n",
       "         9.60224748e-01],\n",
       "       [-1.14182103e-02,  8.72798264e-01,  4.83566448e-02,\n",
       "         9.97951686e-01],\n",
       "       [-1.51460338e-02,  7.62957811e-01,  7.38767907e-02,\n",
       "         1.09500742e+00],\n",
       "       [-9.99311134e-02,  8.45618486e-01,  1.60332173e-01,\n",
       "         1.00495124e+00],\n",
       "       [-1.45312864e-02,  9.27859604e-01,  5.34080565e-02,\n",
       "         1.03742373e+00],\n",
       "       [-2.06980668e-02,  8.22657228e-01,  7.38538653e-02,\n",
       "         1.15439677e+00],\n",
       "       [-9.83903185e-02,  9.00740087e-01,  1.76937014e-01,\n",
       "         1.04630685e+00],\n",
       "       [ 3.24705653e-02, -2.15092003e-02,  1.01297796e-01,\n",
       "         9.17916521e-02],\n",
       "       [ 2.21669860e-02, -1.13287553e-01,  1.31047145e-01,\n",
       "         1.96271285e-01],\n",
       "       [-4.69089821e-02, -4.25151810e-02,  2.42159337e-01,\n",
       "         9.72662941e-02],\n",
       "       [ 3.43903154e-02,  2.21446119e-02,  1.06051996e-01,\n",
       "         1.45053133e-01],\n",
       "       [ 2.19858848e-02, -6.14118874e-02,  1.34690583e-01,\n",
       "         2.53919899e-01],\n",
       "       [-5.18103018e-02, -1.99011713e-03,  2.31934875e-01,\n",
       "         1.49334013e-01],\n",
       "       [ 3.88772078e-02,  7.31331632e-02,  1.03487298e-01,\n",
       "         2.06269592e-01],\n",
       "       [ 2.88468078e-02, -3.91015410e-02,  1.31855488e-01,\n",
       "         3.25104147e-01],\n",
       "       [-4.53327820e-02,  3.82102057e-02,  2.23011762e-01,\n",
       "         2.03563184e-01],\n",
       "       [ 4.09169309e-02,  1.24831177e-01,  1.04453832e-01,\n",
       "         2.56335050e-01],\n",
       "       [ 2.89908014e-02, -1.90418959e-03,  1.28789008e-01,\n",
       "         3.92716050e-01],\n",
       "       [-4.75071371e-02,  9.02313367e-02,  2.19401330e-01,\n",
       "         2.56578475e-01],\n",
       "       [ 4.20365669e-02,  1.74264580e-01,  1.06286392e-01,\n",
       "         3.07095289e-01],\n",
       "       [ 2.79337279e-02,  2.52709240e-02,  1.33736044e-01,\n",
       "         4.40379858e-01],\n",
       "       [-4.45210114e-02,  1.37257740e-01,  2.21795917e-01,\n",
       "         3.08784485e-01],\n",
       "       [ 4.24158163e-02,  2.24571392e-01,  1.08285382e-01,\n",
       "         3.53402257e-01],\n",
       "       [ 2.45882794e-02,  6.66975081e-02,  1.39100373e-01,\n",
       "         4.92566735e-01],\n",
       "       [-4.77628112e-02,  1.84103429e-01,  2.23333389e-01,\n",
       "         3.58907163e-01],\n",
       "       [ 4.20358814e-02,  2.75146037e-01,  1.09569177e-01,\n",
       "         4.02628273e-01],\n",
       "       [ 2.22821236e-02,  1.13148019e-01,  1.41562387e-01,\n",
       "         5.49433172e-01],\n",
       "       [-4.99460474e-02,  2.33449250e-01,  2.22825855e-01,\n",
       "         4.10151809e-01],\n",
       "       [ 4.20775153e-02,  3.25378656e-01,  1.09647498e-01,\n",
       "         4.53787327e-01],\n",
       "       [ 2.20812559e-02,  1.65110141e-01,  1.41997218e-01,\n",
       "         5.93930960e-01],\n",
       "       [-5.15806153e-02,  2.84011424e-01,  2.22791046e-01,\n",
       "         4.61952567e-01],\n",
       "       [ 4.26240377e-02,  3.75492573e-01,  1.10322177e-01,\n",
       "         5.04261017e-01],\n",
       "       [ 2.32172497e-02,  2.17660099e-01,  1.42442942e-01,\n",
       "         6.36651397e-01],\n",
       "       [-5.24218082e-02,  3.34778517e-01,  2.21339077e-01,\n",
       "         5.12585461e-01],\n",
       "       [ 4.15722132e-02,  4.25800771e-01,  1.11475527e-01,\n",
       "         5.51192701e-01],\n",
       "       [ 2.13124901e-02,  2.69153297e-01,  1.43492043e-01,\n",
       "         6.79637134e-01],\n",
       "       [-5.32344580e-02,  3.85776877e-01,  2.21270382e-01,\n",
       "         5.60613394e-01],\n",
       "       [ 4.13344093e-02,  4.75534081e-01,  1.11709535e-01,\n",
       "         5.99813223e-01],\n",
       "       [ 1.98308304e-02,  3.22149813e-01,  1.43991143e-01,\n",
       "         7.30596960e-01],\n",
       "       [-5.30663654e-02,  4.35748756e-01,  2.22607374e-01,\n",
       "         6.10230625e-01],\n",
       "       [ 4.16119434e-02,  5.24762034e-01,  1.10940665e-01,\n",
       "         6.51146650e-01],\n",
       "       [ 2.11054496e-02,  3.75308335e-01,  1.43835023e-01,\n",
       "         7.84835517e-01],\n",
       "       [-5.09179682e-02,  4.85553116e-01,  2.25556687e-01,\n",
       "         6.61519051e-01],\n",
       "       [ 4.26847115e-02,  5.74231923e-01,  1.10989235e-01,\n",
       "         7.01645553e-01],\n",
       "       [ 2.20673159e-02,  4.24608141e-01,  1.45223409e-01,\n",
       "         8.38448286e-01],\n",
       "       [-5.11688218e-02,  5.33709645e-01,  2.26990670e-01,\n",
       "         7.11295247e-01],\n",
       "       [ 4.28721420e-02,  6.24674082e-01,  1.10738188e-01,\n",
       "         7.52147436e-01]], dtype=float32)), ('detection_scores', array([0.6265359 , 0.2936889 , 0.25192142, 0.20616718, 0.1913204 ,\n",
       "       0.1604332 , 0.15446723, 0.1415486 , 0.11828656, 0.11814877,\n",
       "       0.11476233, 0.10969766, 0.10653726, 0.10159062, 0.10148551,\n",
       "       0.10002045, 0.09817052, 0.09612558, 0.08976604, 0.08621871,\n",
       "       0.08558987, 0.08371657, 0.07918405, 0.07910606, 0.07809765,\n",
       "       0.07481884, 0.07269859, 0.07236733, 0.06893085, 0.06840644,\n",
       "       0.06541801, 0.06522028, 0.06448074, 0.06255225, 0.06064721,\n",
       "       0.06016961, 0.0589124 , 0.05887241, 0.05814015, 0.05805825,\n",
       "       0.05760692, 0.05748772, 0.05686764, 0.05662618, 0.0558113 ,\n",
       "       0.05553381, 0.05534597, 0.05525217, 0.05508547, 0.05473169,\n",
       "       0.05413409, 0.05340268, 0.0518377 , 0.05176795, 0.05145653,\n",
       "       0.05106933, 0.04986162, 0.04964989, 0.04947763, 0.04926931,\n",
       "       0.04923582, 0.04903493, 0.04901714, 0.04875199, 0.04811119,\n",
       "       0.04791829, 0.04774244, 0.04629985, 0.04615541, 0.04517397,\n",
       "       0.0450548 , 0.04423787, 0.04401225, 0.04387463, 0.04285467,\n",
       "       0.04208816, 0.04197977, 0.04187399, 0.04184787, 0.04181118,\n",
       "       0.04117427, 0.04101822, 0.04093224, 0.04084128, 0.04066459,\n",
       "       0.04057616, 0.04019975, 0.03996786, 0.03985156, 0.03959007,\n",
       "       0.03921774, 0.03915095, 0.03902882, 0.03899072, 0.03889859,\n",
       "       0.0388864 , 0.03884435, 0.03881   , 0.03880091, 0.03863315],\n",
       "      dtype=float32)), ('detection_classes', array([2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2,\n",
       "       1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1,\n",
       "       1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 1,\n",
       "       2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2,\n",
       "       2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2])), ('raw_detection_scores', array([[0.0063659 , 0.00957629, 0.01726895],\n",
       "       [0.00784968, 0.00787167, 0.00388482],\n",
       "       [0.00655251, 0.00480628, 0.00508951],\n",
       "       [0.00593644, 0.01111954, 0.01502135],\n",
       "       [0.00797899, 0.00907007, 0.00363227],\n",
       "       [0.00619086, 0.005126  , 0.0036971 ],\n",
       "       [0.00560285, 0.00924491, 0.01339287],\n",
       "       [0.00702498, 0.0125342 , 0.00536911],\n",
       "       [0.00595824, 0.00389699, 0.00332596],\n",
       "       [0.00600891, 0.00863736, 0.01448431],\n",
       "       [0.00662624, 0.01202242, 0.01006292],\n",
       "       [0.00688822, 0.00301451, 0.00367079],\n",
       "       [0.00602937, 0.00763404, 0.01368214],\n",
       "       [0.00646357, 0.00872124, 0.01047403],\n",
       "       [0.00707201, 0.00246122, 0.00386055],\n",
       "       [0.0060859 , 0.00643732, 0.01198675],\n",
       "       [0.00649604, 0.00691776, 0.00930626],\n",
       "       [0.00727527, 0.00217339, 0.00430005],\n",
       "       [0.00612491, 0.00614017, 0.01054522],\n",
       "       [0.00643588, 0.00685818, 0.00990614],\n",
       "       [0.00724194, 0.00204173, 0.00414539],\n",
       "       [0.00613333, 0.00620099, 0.01060273],\n",
       "       [0.00631444, 0.00741015, 0.01011608],\n",
       "       [0.00721141, 0.00208255, 0.00424519],\n",
       "       [0.00624079, 0.00673863, 0.01096775],\n",
       "       [0.00633243, 0.00788253, 0.00951794],\n",
       "       [0.00728922, 0.00233915, 0.00434818],\n",
       "       [0.00641328, 0.00699838, 0.01121595],\n",
       "       [0.00641605, 0.00757498, 0.00938932],\n",
       "       [0.00725493, 0.0024919 , 0.00458933],\n",
       "       [0.00639531, 0.00633035, 0.01090941],\n",
       "       [0.00636582, 0.00696373, 0.00968667],\n",
       "       [0.00722169, 0.00236473, 0.00464918],\n",
       "       [0.0063483 , 0.00567203, 0.01028662],\n",
       "       [0.00640523, 0.00699674, 0.01085329],\n",
       "       [0.00742979, 0.00215183, 0.00450676],\n",
       "       [0.00634632, 0.00568589, 0.01034312],\n",
       "       [0.00635581, 0.00659195, 0.0107311 ],\n",
       "       [0.00743235, 0.00208207, 0.00438507],\n",
       "       [0.00636445, 0.00560554, 0.0096636 ],\n",
       "       [0.00633315, 0.00672085, 0.01220223],\n",
       "       [0.0074994 , 0.00186868, 0.00420856],\n",
       "       [0.00630519, 0.00587356, 0.01033858],\n",
       "       [0.00635377, 0.00677403, 0.01289998],\n",
       "       [0.0074603 , 0.00181399, 0.00426028],\n",
       "       [0.00607424, 0.00621308, 0.01176958],\n",
       "       [0.00638055, 0.00702417, 0.0115938 ],\n",
       "       [0.00731221, 0.00186253, 0.00410283],\n",
       "       [0.00596397, 0.00686155, 0.01339067],\n",
       "       [0.00645687, 0.00780916, 0.00949894],\n",
       "       [0.00717345, 0.00209002, 0.00378829],\n",
       "       [0.00599626, 0.00796484, 0.01407756],\n",
       "       [0.0066939 , 0.00969753, 0.00914547],\n",
       "       [0.00718118, 0.00283648, 0.00457525],\n",
       "       [0.00638032, 0.01217058, 0.01704402],\n",
       "       [0.00771733, 0.00937491, 0.00457292],\n",
       "       [0.00668829, 0.0052044 , 0.00468058],\n",
       "       [0.00689151, 0.01048447, 0.01981927],\n",
       "       [0.00743116, 0.00934178, 0.00671232],\n",
       "       [0.00651638, 0.00494918, 0.00687826],\n",
       "       [0.00580033, 0.00900987, 0.01669431],\n",
       "       [0.00785486, 0.00801327, 0.00262936],\n",
       "       [0.00596039, 0.00918786, 0.00723548],\n",
       "       [0.00594854, 0.00850237, 0.00985066],\n",
       "       [0.00806751, 0.00785088, 0.00220266],\n",
       "       [0.00712957, 0.006131  , 0.00477685],\n",
       "       [0.00514553, 0.00579061, 0.0062778 ],\n",
       "       [0.0074076 , 0.01192141, 0.00314332],\n",
       "       [0.00670176, 0.0038181 , 0.00329249],\n",
       "       [0.00568391, 0.0065804 , 0.00721615],\n",
       "       [0.00720548, 0.01173484, 0.00606582],\n",
       "       [0.00757878, 0.00309864, 0.00345048],\n",
       "       [0.00553312, 0.00590974, 0.00666627],\n",
       "       [0.00694769, 0.01138132, 0.00759392],\n",
       "       [0.007664  , 0.0025967 , 0.00378168],\n",
       "       [0.00561671, 0.00518357, 0.00580856],\n",
       "       [0.00678215, 0.00885145, 0.00762604],\n",
       "       [0.00776437, 0.00219364, 0.00422298],\n",
       "       [0.00563191, 0.0050058 , 0.00533153],\n",
       "       [0.00694439, 0.00905515, 0.0096945 ],\n",
       "       [0.00809423, 0.00195813, 0.00448798],\n",
       "       [0.00546696, 0.00467051, 0.00515245],\n",
       "       [0.00685141, 0.00905393, 0.00964204],\n",
       "       [0.00808529, 0.00193045, 0.00442504],\n",
       "       [0.00534418, 0.00470985, 0.00509711],\n",
       "       [0.00681182, 0.00975451, 0.00875437],\n",
       "       [0.00816027, 0.00209286, 0.00406302],\n",
       "       [0.00555004, 0.00549727, 0.00541285],\n",
       "       [0.00694679, 0.00981706, 0.00805515],\n",
       "       [0.00826284, 0.00236496, 0.0044754 ],\n",
       "       [0.00583293, 0.00534313, 0.00559494],\n",
       "       [0.00692104, 0.00885176, 0.0084466 ],\n",
       "       [0.00832722, 0.00232839, 0.00496485],\n",
       "       [0.00578422, 0.00480687, 0.00555496],\n",
       "       [0.00688469, 0.00802115, 0.00859023],\n",
       "       [0.00803505, 0.00219918, 0.00521546],\n",
       "       [0.00584738, 0.00446415, 0.0054386 ],\n",
       "       [0.0068802 , 0.00749525, 0.0083217 ],\n",
       "       [0.00810842, 0.00206015, 0.00514652],\n",
       "       [0.00577893, 0.00443267, 0.00512918]], dtype=float32)), ('detection_boxes', array([[0.37094358, 0.07923913, 0.5373101 , 0.83115363],\n",
       "       [0.37154216, 0.4069959 , 0.41281873, 0.5861888 ],\n",
       "       [0.36709154, 0.0876731 , 0.50753593, 0.34671262],\n",
       "       [0.3769577 , 0.35508603, 0.49206638, 0.64130753],\n",
       "       [0.6484789 , 0.5765608 , 0.77432173, 0.8206251 ],\n",
       "       [0.36569357, 0.36507827, 0.49525762, 0.79891914],\n",
       "       [0.41208217, 0.41726086, 0.5254817 , 0.8215442 ],\n",
       "       [0.37566277, 0.37001687, 0.42800817, 0.6449477 ],\n",
       "       [0.6484789 , 0.5765608 , 0.77432173, 0.8206251 ],\n",
       "       [0.16664241, 0.        , 0.47862846, 0.08721897],\n",
       "       [0.37037718, 0.3722438 , 0.41326934, 0.5303141 ],\n",
       "       [0.3927924 , 0.4098965 , 0.46178466, 0.5718878 ],\n",
       "       [0.36588988, 0.36826825, 0.4324822 , 0.7411847 ],\n",
       "       [0.42488426, 0.540031  , 0.5203465 , 0.83132   ],\n",
       "       [0.44482914, 0.6164867 , 0.51128393, 0.7703882 ],\n",
       "       [0.67589605, 0.5793539 , 0.7726642 , 0.6973108 ],\n",
       "       [0.3644682 , 0.614363  , 0.40887532, 0.78157395],\n",
       "       [0.39693338, 0.61414653, 0.45537782, 0.77295846],\n",
       "       [0.38164794, 0.49798948, 0.48508936, 0.8197523 ],\n",
       "       [0.339673  , 0.14431256, 0.5244546 , 0.31588024],\n",
       "       [0.4076218 , 0.34520042, 0.51855457, 0.6563473 ],\n",
       "       [0.44389588, 0.66549855, 0.51005024, 0.81254905],\n",
       "       [0.67141   , 0.61836666, 0.76951677, 0.7585315 ],\n",
       "       [0.39919132, 0.3699931 , 0.46787953, 0.5181044 ],\n",
       "       [0.03915685, 0.        , 0.5851692 , 0.7701103 ],\n",
       "       [0.4301908 , 0.37524083, 0.51739395, 0.49408546],\n",
       "       [0.7563889 , 0.06091803, 1.        , 0.9484189 ],\n",
       "       [0.669714  , 0.72332394, 0.76646817, 0.83683586],\n",
       "       [0.34348035, 0.        , 0.5912778 , 0.83291006],\n",
       "       [0.4301908 , 0.37524083, 0.51739395, 0.49408546],\n",
       "       [0.2676227 , 0.03096023, 0.66608155, 0.9293703 ],\n",
       "       [0.6421716 , 0.6216699 , 0.7364124 , 0.7523123 ],\n",
       "       [0.39641085, 0.6649516 , 0.45714995, 0.8100067 ],\n",
       "       [0.66884667, 0.6606448 , 0.76740843, 0.79705375],\n",
       "       [0.44101143, 0.72619194, 0.5090126 , 0.83388275],\n",
       "       [0.26692972, 0.        , 0.37398717, 0.06794688],\n",
       "       [0.5240422 , 0.        , 0.9810615 , 0.8812907 ],\n",
       "       [0.3191418 , 0.        , 0.41713637, 0.06866497],\n",
       "       [0.43575808, 0.4188636 , 0.5150615 , 0.5514658 ],\n",
       "       [0.48543715, 0.62135327, 0.5458518 , 0.7610141 ],\n",
       "       [0.358306  , 0.6691706 , 0.40945482, 0.8087733 ],\n",
       "       [0.38728544, 0.12054853, 0.51869565, 0.4195361 ],\n",
       "       [0.48382628, 0.671385  , 0.54509056, 0.8069367 ],\n",
       "       [0.00340816, 0.        , 0.52706254, 0.8419332 ],\n",
       "       [0.37479132, 0.12198082, 0.4795848 , 0.2645782 ],\n",
       "       [0.859828  , 0.10452273, 1.        , 0.95234334],\n",
       "       [0.5102582 , 0.1099593 , 0.9673122 , 1.        ],\n",
       "       [0.36997002, 0.15806524, 0.4862895 , 0.30613375],\n",
       "       [0.00511426, 0.        , 1.        , 0.34091428],\n",
       "       [0.6248517 , 0.02412897, 0.99555945, 0.96005017],\n",
       "       [0.6450075 , 0.58521783, 0.73380184, 0.69281983],\n",
       "       [0.67141   , 0.61836666, 0.76951677, 0.7585315 ],\n",
       "       [0.14785773, 0.04617649, 0.885825  , 0.952435  ],\n",
       "       [0.63562506, 0.6668827 , 0.7319508 , 0.7918202 ],\n",
       "       [0.27777523, 0.8725861 , 0.35995758, 0.99711365],\n",
       "       [0.8722132 , 0.8229528 , 0.9549003 , 0.94641596],\n",
       "       [0.8673135 , 0.86125714, 0.95643544, 0.9965343 ],\n",
       "       [0.43302518, 0.3332571 , 0.5114679 , 0.435649  ],\n",
       "       [0.37094358, 0.07923913, 0.5373101 , 0.83115363],\n",
       "       [0.44101143, 0.72619194, 0.5090126 , 0.83388275],\n",
       "       [0.5914932 , 0.6016316 , 0.7891305 , 0.7835805 ],\n",
       "       [0.42357382, 0.        , 0.52093416, 0.07849301],\n",
       "       [0.5564111 , 0.06241536, 0.83804625, 0.92268914],\n",
       "       [0.3752652 , 0.        , 0.46627864, 0.07444302],\n",
       "       [0.3625702 , 0.5181642 , 0.43035814, 0.8516894 ],\n",
       "       [0.32316232, 0.8733264 , 0.39787215, 0.99942195],\n",
       "       [0.        , 0.03853777, 0.42499897, 0.9299331 ],\n",
       "       [0.16664241, 0.        , 0.47862846, 0.08721897],\n",
       "       [0.68843406, 0.13010105, 0.76512045, 0.5114509 ],\n",
       "       [0.03641362, 0.06883246, 0.4822235 , 1.        ],\n",
       "       [0.1266889 , 0.        , 0.91915864, 0.27794755],\n",
       "       [0.36709154, 0.0876731 , 0.50753593, 0.34671262],\n",
       "       [0.341954  , 0.        , 1.        , 0.68484926],\n",
       "       [0.86083335, 0.7416471 , 0.9739416 , 1.        ],\n",
       "       [0.05326009, 0.        , 0.92197806, 0.12250157],\n",
       "       [0.76013917, 0.8469954 , 0.9892294 , 1.        ],\n",
       "       [0.83007365, 0.8627542 , 0.9120584 , 1.        ],\n",
       "       [0.37447214, 0.21420681, 0.48246825, 0.34036982],\n",
       "       [0.69858164, 0.1635271 , 0.7524621 , 0.31769556],\n",
       "       [0.8722132 , 0.8229528 , 0.9549003 , 0.94641596],\n",
       "       [0.63491833, 0.72674763, 0.7236291 , 0.8323319 ],\n",
       "       [0.16969305, 0.        , 0.26809132, 0.07646279],\n",
       "       [0.43914235, 0.03449985, 1.        , 0.24688867],\n",
       "       [0.1607875 , 0.        , 0.49915877, 0.8050082 ],\n",
       "       [0.13424432, 0.        , 0.45024395, 0.13905087],\n",
       "       [0.8673135 , 0.86125714, 0.95643544, 0.9965343 ],\n",
       "       [0.34430575, 0.3338887 , 0.54811764, 0.8293626 ],\n",
       "       [0.6421716 , 0.6216699 , 0.7364124 , 0.7523123 ],\n",
       "       [0.4423101 , 0.57181317, 0.5110891 , 0.7101278 ],\n",
       "       [0.66884667, 0.6606448 , 0.76740843, 0.79705375],\n",
       "       [0.86083335, 0.7416471 , 0.9739416 , 1.        ],\n",
       "       [0.22384763, 0.        , 0.77204263, 1.        ],\n",
       "       [0.        , 0.        , 0.821137  , 0.558264  ],\n",
       "       [0.12915567, 0.03355893, 0.87363434, 0.9686712 ],\n",
       "       [0.17321539, 0.01890972, 0.2645953 , 0.11809535],\n",
       "       [0.64739734, 0.11616176, 0.7088252 , 0.24211645],\n",
       "       [0.42175516, 0.12467413, 0.5160206 , 0.25275192],\n",
       "       [0.        , 0.15906006, 0.53502965, 1.        ],\n",
       "       [0.        , 0.        , 0.3882393 , 0.9843461 ],\n",
       "       [0.7035971 , 0.3128651 , 0.75215846, 0.4774932 ]], dtype=float32)), ('num_detections', 100)])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(detections['detection_scores'])\n",
    "# print(detections['detection_boxes'])\n",
    "# print(detections['detection_classes'])\n",
    "detections.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height, _ = image_np.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "raw_detection_boxes <br>\n",
    "detection_scores<br>\n",
    "detection_boxes<br>\n",
    "detection_anchor_indices<br>\n",
    "raw_detection_scores<br>\n",
    "detection_classes<br>\n",
    "detection_multiclass_scores<br>\n",
    "num_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 265 118 171\n"
     ]
    }
   ],
   "source": [
    "ymin, xmin, ymax, xmax = detections['detection_boxes'][0]\n",
    "(left, right, top, bottom) = (xmin*width, xmax*width, ymin*height, ymax*height)\n",
    "print(int(left), int(right), int(top), int(bottom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_top = cv.circle(image_np, (int(top), int(top+right)), 2, (0, 266, 0), 2)\n",
    "# im_bot = \n",
    "# im_right = \n",
    "# im_lrft = \n",
    "\n",
    "Image.fromarray(im_top).save('top.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv.rectangle(image_np, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 3)\n",
    "Image.fromarray(im).save('test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_im = image_np[int(top):int(bottom), int(left):int(right)]\n",
    "Image.fromarray(cropped_im).save('cropped-logo.jpg')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bangkit-ws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
