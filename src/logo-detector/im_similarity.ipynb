{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 20:56:58.321812: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-04 20:56:58.354740: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-04 20:56:58.355657: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-04 20:56:59.152054: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '/home/irizqy/ml_ws/bangkit-ws/data/bizz.it-sim_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path_arr = os.listdir(DATASET_PATH)\n",
    "im_classes_arr = []\n",
    "\n",
    "for file in im_path_arr:\n",
    "    im_classes_arr.append(file.split('_')[0])\n",
    "\n",
    "im_classes_arr = np.asarray(im_classes_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(im_classes_arr)\n",
    "\n",
    "dict_keys = {val:key for key, val in enumerate(classes.flatten())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_im_path = [np.where(im_classes_arr == cls)[0] for cls in classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_pairs(ims_arr):\n",
    "    im_pairs = []\n",
    "    labels = []\n",
    "\n",
    "    for file in ims_arr:\n",
    "        file_cls = file.split('_')[0]\n",
    "        cls = dict_keys[file_cls]\n",
    "\n",
    "        current_im = cv.imread(os.path.join(DATASET_PATH, file))\n",
    "        # current_im = cv.cvtColor(current_im, cv.COLOR_BGR2RGB)\n",
    "        current_im = cv.cvtColor(current_im, cv.COLOR_BGR2GRAY)\n",
    "        current_im = cv.resize(current_im, (150, 150))\n",
    "        current_im = current_im / 255\n",
    "\n",
    "        pos_idx = np.random.choice(grouped_im_path[cls], 1)[0]\n",
    "        pos_pair_im = cv.imread(os.path.join(DATASET_PATH, im_path_arr[pos_idx]))\n",
    "        # pos_pair_im = cv.cvtColor(pos_pair_im, cv.COLOR_BGR2RGB)\n",
    "        pos_pair_im = cv.cvtColor(pos_pair_im, cv.COLOR_BGR2GRAY)\n",
    "        pos_pair_im = cv.resize(pos_pair_im, (150, 150))\n",
    "        pos_pair_im = pos_pair_im / 255\n",
    "\n",
    "        im_pairs.append((current_im, pos_pair_im))\n",
    "        labels.append(1)\n",
    "\n",
    "        neg_idx = np.random.choice(np.where(im_classes_arr != file_cls)[0], 1)[0]\n",
    "        neg_pair_im = cv.imread(os.path.join(DATASET_PATH, im_path_arr[neg_idx]))\n",
    "        # neg_pair_im = cv.cvtColor(neg_pair_im, cv.COLOR_BGR2RGB)\n",
    "        neg_pair_im = cv.cvtColor(neg_pair_im, cv.COLOR_BGR2GRAY)\n",
    "        neg_pair_im = cv.resize(neg_pair_im, (150, 150))\n",
    "        neg_pair_im = neg_pair_im / 255\n",
    "\n",
    "        im_pairs.append((current_im, neg_pair_im))\n",
    "        labels.append(0)\n",
    "\n",
    "    return np.asarray(im_pairs), np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs, train_labels = make_pairs(im_path_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_to_test(ims_arr, ims_label, percentage):\n",
    "    arr_length = ims_arr.shape[0]\n",
    "    num_of_data = int((percentage/100) * arr_length)\n",
    "    im_pairs = []\n",
    "    im_labels = []\n",
    "\n",
    "\n",
    "    for i in range(num_of_data):\n",
    "        rand_i = np.random.randint(arr_length - 1)\n",
    "        im_pairs.append(ims_arr[rand_i])\n",
    "        im_labels.append(ims_label[rand_i])\n",
    "    \n",
    "    return np.asarray(im_pairs), np.asarray(im_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pairs, test_label = split_train_to_test(train_pairs, train_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 20\n",
    "h = 15\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "columns = 8\n",
    "rows = 8\n",
    "for index, i in enumerate(range(1, (columns*rows +1)//2)):\n",
    "    img = train_pairs[index][0]\n",
    "    fig.add_subplot(rows, columns, 2*i - 1) \n",
    "    if i % 2 == 1:\n",
    "        plt.title('1')\n",
    "    else:\n",
    "        plt.title('0')\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    img = train_pairs[index][1]\n",
    "    fig.add_subplot(rows, columns, 2*i)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np_ims[2][0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (150, 150, 1)\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseModel:\n",
    "\n",
    "    def __init__(self, input_shape, embedding_dim=300):\n",
    "        self.input_shape = input_shape\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "    def _build(self):\n",
    "        inputs = tf.keras.layers.Input(self.input_shape)\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(inputs)\n",
    "        x = tf.keras.layers.MaxPooling2D()(x)\n",
    "        x = tf.keras.layers.Dropout(.1)(x)\n",
    "\n",
    "        x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "        x = tf.keras.layers.MaxPooling2D()(x)\n",
    "\n",
    "        # x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(x)\n",
    "        # x = tf.keras.layers.MaxPooling2D()(x)\n",
    "\n",
    "        # x = tf.keras.layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
    "        # x = tf.keras.layers.MaxPooling2D()(x)\n",
    "        # x = tf.keras.layers.Dropout(.3)(x)\n",
    "\n",
    "        # pooled_output = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        pooled_output = tf.keras.layers.Flatten()(x)\n",
    "        outputs = tf.keras.layers.Dense(self.embedding_dim)(pooled_output)\n",
    "\n",
    "        model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SiameseModel(IMG_SHAPE)\n",
    "\n",
    "featureExtractor = sm._build()\n",
    "featureExtractor.summary()\n",
    "\n",
    "# base_cnn =  tf.keras.applications.resnet.ResNet50(\n",
    "#     weights=None, input_shape=IMG_SHAPE, include_top=False\n",
    "# )\n",
    "\n",
    "# cnn_model = base_cnn.get_layer('conv5_block3_2_conv')\n",
    "\n",
    "# flatten = tf.keras.layers.Flatten()(cnn_model.output)\n",
    "# dense_1 = tf.keras.layers.Dense(units=256, activation='relu')(flatten)\n",
    "# dense_2 = tf.keras.layers.Dense(units=128, activation='relu')(dense_1)\n",
    "\n",
    "# featureExtractor = tf.keras.Model(base_cnn.input, dense_2)\n",
    "\n",
    "# for layer in featureExtractor.layers[:-25]:\n",
    "#     layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureExtractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vectors):\n",
    "\t# unpack the vectors into separate lists\n",
    "\t(feats_A, feats_B) = vectors\n",
    "\t# compute the sum of squared distances between the vectors\n",
    "\tsum_squared = K.sum(K.square(feats_A - feats_B), axis=1,\n",
    "\t\tkeepdims=True)\n",
    "\t# return the euclidean distance between the vectors\n",
    "\treturn K.sqrt(K.maximum(sum_squared, K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vectors):\n",
    "    (featsA, featsB) = vectors\n",
    "    sum_product = K.sum(featsA*featsB)\n",
    "    sum_squared_featsA = K.sqrt(K.sum(featsA**2, keepdims=1, axis=1))\n",
    "    sum_squared_featsB = K.sqrt(K.sum(featsB**2, keepdims=1, axis=1))\n",
    "    sum_mul_feats = sum_squared_featsA * sum_squared_featsB\n",
    "\n",
    "    return sum_product / sum_mul_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(H):\n",
    "\t# construct a plot that plots and saves the training history\n",
    "\tplt.style.use(\"ggplot\")\n",
    "\tplt.figure()\n",
    "\tplt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
    "\t# plt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
    "\tplt.plot(H.history[\"accuracy\"], label=\"train_acc\")\n",
    "\t# plt.plot(H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "\tplt.title(\"Training Loss and Accuracy\")\n",
    "\tplt.xlabel(\"Epoch #\")\n",
    "\tplt.ylabel(\"Loss/Accuracy\")\n",
    "\tplt.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the siamese network\n",
    "print(\"[INFO] building siamese network...\")\n",
    "imgA = tf.keras.layers.Input(shape=IMG_SHAPE)\n",
    "imgB = tf.keras.layers.Input(shape=IMG_SHAPE)\n",
    "featsA = featureExtractor(imgA)\n",
    "featsB = featureExtractor(imgB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, construct the siamese network\n",
    "distance = tf.keras.layers.Lambda(euclidean_distance)([featsA, featsB])\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "model = tf.keras.Model(inputs=[imgA, imgB], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "# compile the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
    "\tmetrics=[\"accuracy\"])\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "history = model.fit(\n",
    "\t[np_ims[:, 0], np_ims[:, 1]], np_labels[:],\n",
    "\t# validation_data=([np_ims[251:, 0], np_ims[251:, 1]], np_labels[251:]),\n",
    "\tbatch_size=BATCH_SIZE, \n",
    "\tepochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/home/irizqy/ml_ws/bangkit-ws/src/logo-detector/im_similar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "\n",
    "preds = []\n",
    "\n",
    "test_data = os.listdir('/home/irizqy/ml_ws/bangkit-ws/data/bizz.it-sim_dataset')\n",
    "\n",
    "im1 = Image.open('/home/irizqy/ml_ws/bangkit-ws/src/ops/cropped-logo.jpg').resize((150, 150))\n",
    "im1 = ImageOps.grayscale(im1)\n",
    "im1.show()\n",
    "im1 = np.asarray(im1)\n",
    "im1 = im1 / 255\n",
    "\n",
    "image1 = np.expand_dims(im1, 0)\n",
    "\n",
    "im2 = Image.open('/home/irizqy/ml_ws/bangkit-ws/data/bizz.it-sim_dataset/mcd_85.jpg').resize((150, 150))\n",
    "# im2 = Image.open('/home/irizqy/ml_ws/bangkit-ws/data/LogoDet-3K/Food/mcdonalds/3.jpg').resize((150, 150))\n",
    "im2 = ImageOps.grayscale(im2)\n",
    "im2.show()\n",
    "im2 = np.asarray(im2)\n",
    "im2 = im2 / 255\n",
    "\n",
    "image2 = np.expand_dims(im2, 0)\n",
    "model.predict((image1, image2))[0][0]\n",
    "\n",
    "# for file in test_data:\n",
    "#     im2 = Image.open(os.path.join('/home/irizqy/ml_ws/bangkit-ws/data/bizz.it-sim_dataset', file)).resize((150, 150))\n",
    "#     im2 = ImageOps.grayscale(im2)\n",
    "#     im2 = np.asarray(im2)\n",
    "#     im2 = im2 / 255\n",
    "\n",
    "#     image2 = np.expand_dims(im2, 0)\n",
    "#     pred = model.predict((image1, image2))[0][0]\n",
    "#     preds.append(pred)\n",
    "\n",
    "# preds = np.asarray(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = np.argmax(preds)\n",
    "print(max_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[max_idx]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bangkit-ws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
