{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import utils.data_utils as du\n",
    "import utils.model_helper as mh\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '/home/irizqy/ml_ws/bangkit-ws/data/bizz.it-sim_dataset'\n",
    "IMAGE_SHAPE = (150, 150, 3)\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_pairs, test_pairs) = du.make_train_test_pairs(DATASET_PATH, .1)\n",
    "train_pairs.shape, test_pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 9\n",
    "h = 8\n",
    "\n",
    "du.visualize(train_pairs, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cnn_model = tf.keras.applications.resnet50.ResNet50(input_shape=IMAGE_SHAPE, weights='imagenet', include_top=False)\n",
    "\n",
    "embedding_model = tf.keras.Sequential([\n",
    "    base_cnn_model,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(256),\n",
    "], name='base_embedding_model')\n",
    "\n",
    "trainable = False\n",
    "for layer in base_cnn_model.layers:\n",
    "    if layer.name == 'conv4_block2_out':\n",
    "        trainable = True\n",
    "    layer.trainable = trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    This layer is responsible for computing the distance between the anchor\n",
    "    embedding and the positive embedding, and the anchor embedding and the\n",
    "    negative embedding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, anchor, positive, negative):\n",
    "        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n",
    "        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n",
    "        return (ap_distance, an_distance)\n",
    "    \n",
    "anchor_input = tf.keras.layers.Input(name=\"anchor\", shape=IMAGE_SHAPE)\n",
    "positive_input = tf.keras.layers.Input(name=\"positive\", shape=IMAGE_SHAPE)\n",
    "negative_input = tf.keras.layers.Input(name=\"negative\", shape=IMAGE_SHAPE)\n",
    "\n",
    "distances = DistanceLayer()(\n",
    "    embedding_model(tf.keras.applications.resnet.preprocess_input(anchor_input)),\n",
    "    embedding_model(tf.keras.applications.resnet.preprocess_input(positive_input)),\n",
    "    embedding_model(tf.keras.applications.resnet.preprocess_input(negative_input)),\n",
    ")\n",
    "\n",
    "siamese_network = tf.keras.Model(\n",
    "    inputs=[anchor_input, positive_input, negative_input], outputs=distances\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseModel(tf.keras.Model):\n",
    "    \"\"\"The Siamese Network model with a custom training and testing loops.\n",
    "\n",
    "    Computes the triplet loss using the three embeddings produced by the\n",
    "    Siamese Network.\n",
    "\n",
    "    The triplet loss is defined as:\n",
    "       L(A, P, N) = max(‖f(A) - f(P)‖² - ‖f(A) - f(N)‖² + margin, 0)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, siamese_network, margin=0.5):\n",
    "        super().__init__()\n",
    "        self.siamese_network = siamese_network\n",
    "        self.margin = margin\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.siamese_network(inputs)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # GradientTape is a context manager that records every operation that\n",
    "        # you do inside. We are using it here to compute the loss so we can get\n",
    "        # the gradients and apply them using the optimizer specified in\n",
    "        # `compile()`.\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self._compute_loss(data)\n",
    "\n",
    "        # Storing the gradients of the loss function with respect to the\n",
    "        # weights/parameters.\n",
    "        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n",
    "\n",
    "        # Applying the gradients on the model using the specified optimizer\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.siamese_network.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Let's update and return the training loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        loss = self._compute_loss(data)\n",
    "\n",
    "        # Let's update and return the loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def _compute_loss(self, data):\n",
    "        # The output of the network is a tuple containing the distances\n",
    "        # between the anchor and the positive example, and the anchor and\n",
    "        # the negative example.\n",
    "        ap_distance, an_distance = self.siamese_network(data)\n",
    "\n",
    "        # Computing the Triplet Loss by subtracting both distances and\n",
    "        # making sure we don't get a negative value.\n",
    "        loss = ap_distance - an_distance\n",
    "        loss = tf.maximum(loss + self.margin, 0.0)\n",
    "        return loss\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We need to list our metrics here so the `reset_states()` can be\n",
    "        # called automatically.\n",
    "        return [self.loss_tracker]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = SiameseModel(siamese_network)\n",
    "siamese_model.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "siamese_model.fit([train_pairs[:, 0], train_pairs[:, 1], train_pairs[:, 2]],\n",
    "                  epochs=20,\n",
    "                  validation_data=[test_pairs[:, 0], test_pairs[:, 1], test_pairs[:, 2]]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.save('/home/irizqy/ml_ws/bangkit-ws/src/logo-detector/triplet_im_similar/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_path = '/home/irizqy/Downloads/ct_3.png'\n",
    "target_path = '/home/irizqy/Downloads/franchise'\n",
    "\n",
    "anchor = mh.adjust_im(anchor_path, (150, 150)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]]\n",
      "[[[[0.88627451 0.1254902  0.16862745]\n",
      "   [0.88627451 0.1254902  0.16862745]\n",
      "   [0.88627451 0.1254902  0.16862745]\n",
      "   ...\n",
      "   [0.81960784 0.10980392 0.18431373]\n",
      "   [0.81960784 0.10980392 0.18431373]\n",
      "   [0.81176471 0.10980392 0.18431373]]\n",
      "\n",
      "  [[0.88627451 0.1254902  0.16862745]\n",
      "   [0.88627451 0.1254902  0.16862745]\n",
      "   [0.88627451 0.1254902  0.16862745]\n",
      "   ...\n",
      "   [0.81960784 0.10980392 0.18431373]\n",
      "   [0.81960784 0.10980392 0.18431373]\n",
      "   [0.81176471 0.10980392 0.18431373]]\n",
      "\n",
      "  [[0.88627451 0.1254902  0.16862745]\n",
      "   [0.88627451 0.1254902  0.16862745]\n",
      "   [0.88627451 0.1254902  0.16862745]\n",
      "   ...\n",
      "   [0.81960784 0.10980392 0.18431373]\n",
      "   [0.81960784 0.10980392 0.18431373]\n",
      "   [0.81176471 0.10980392 0.18431373]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.80784314 0.12156863 0.18823529]\n",
      "   [0.80784314 0.12156863 0.18823529]\n",
      "   [0.80784314 0.12156863 0.18823529]\n",
      "   ...\n",
      "   [0.76470588 0.12156863 0.21568627]\n",
      "   [0.76470588 0.12156863 0.21568627]\n",
      "   [0.74901961 0.1254902  0.21176471]]\n",
      "\n",
      "  [[0.80784314 0.12156863 0.18823529]\n",
      "   [0.80784314 0.12156863 0.18823529]\n",
      "   [0.80784314 0.12156863 0.18823529]\n",
      "   ...\n",
      "   [0.76470588 0.12156863 0.21568627]\n",
      "   [0.76470588 0.12156863 0.21568627]\n",
      "   [0.74901961 0.12941176 0.21176471]]\n",
      "\n",
      "  [[0.80784314 0.12156863 0.18823529]\n",
      "   [0.80784314 0.12156863 0.18823529]\n",
      "   [0.80784314 0.12156863 0.18823529]\n",
      "   ...\n",
      "   [0.76470588 0.12156863 0.21568627]\n",
      "   [0.76470588 0.12156863 0.21568627]\n",
      "   [0.74901961 0.12941176 0.21176471]]]]\n",
      "[[[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]]\n",
      "[[[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]]\n",
      "[[[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]]\n",
      "[[[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]]\n",
      "[[[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]]\n",
      "[[[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]]\n",
      "[[[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]]\n",
      "[[[[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.01176471 0.01176471 0.01176471]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[0.29019608 0.29019608 0.29019608]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[0.96862745 0.96862745 0.96862745]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]]]\n",
      "[[[[0.79607843 0.21960784 0.18823529]\n",
      "   [0.79215686 0.21568627 0.18431373]\n",
      "   [0.79215686 0.21568627 0.18431373]\n",
      "   ...\n",
      "   [0.76862745 0.12941176 0.09411765]\n",
      "   [0.76862745 0.12941176 0.09411765]\n",
      "   [0.76862745 0.12941176 0.09411765]]\n",
      "\n",
      "  [[0.79215686 0.21568627 0.18431373]\n",
      "   [0.79215686 0.21568627 0.18431373]\n",
      "   [0.79215686 0.21568627 0.18431373]\n",
      "   ...\n",
      "   [0.76862745 0.12941176 0.09411765]\n",
      "   [0.76862745 0.12941176 0.09411765]\n",
      "   [0.76862745 0.12941176 0.09411765]]\n",
      "\n",
      "  [[0.79215686 0.21568627 0.18431373]\n",
      "   [0.79215686 0.21568627 0.18431373]\n",
      "   [0.79215686 0.21568627 0.18431373]\n",
      "   ...\n",
      "   [0.76862745 0.12941176 0.09411765]\n",
      "   [0.76862745 0.12941176 0.09411765]\n",
      "   [0.76862745 0.12941176 0.09411765]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.76862745 0.12941176 0.09411765]\n",
      "   [0.76862745 0.12941176 0.09411765]\n",
      "   [0.76862745 0.12941176 0.09411765]\n",
      "   ...\n",
      "   [0.76862745 0.12941176 0.09411765]\n",
      "   [0.76862745 0.12941176 0.09411765]\n",
      "   [0.76862745 0.12941176 0.09411765]]\n",
      "\n",
      "  [[0.76862745 0.12941176 0.09411765]\n",
      "   [0.76862745 0.12941176 0.09411765]\n",
      "   [0.76862745 0.12941176 0.09411765]\n",
      "   ...\n",
      "   [0.76862745 0.12941176 0.09411765]\n",
      "   [0.76862745 0.12941176 0.09411765]\n",
      "   [0.76862745 0.12941176 0.09411765]]\n",
      "\n",
      "  [[0.76862745 0.12941176 0.09411765]\n",
      "   [0.76862745 0.12941176 0.09411765]\n",
      "   [0.76862745 0.12941176 0.09411765]\n",
      "   ...\n",
      "   [0.76862745 0.12941176 0.09411765]\n",
      "   [0.76862745 0.12941176 0.09411765]\n",
      "   [0.76862745 0.12941176 0.09411765]]]]\n",
      "[[[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]]\n",
      "[[[[0.96862745 0.96862745 0.96862745]\n",
      "   [0.96862745 0.96862745 0.96862745]\n",
      "   [0.96862745 0.96862745 0.96862745]\n",
      "   ...\n",
      "   [0.96862745 0.96862745 0.96862745]\n",
      "   [0.96862745 0.96862745 0.96862745]\n",
      "   [0.96862745 0.96862745 0.96862745]]\n",
      "\n",
      "  [[0.96862745 0.96862745 0.96862745]\n",
      "   [0.96862745 0.96862745 0.96862745]\n",
      "   [0.96862745 0.96862745 0.96862745]\n",
      "   ...\n",
      "   [0.96862745 0.96862745 0.96862745]\n",
      "   [0.96862745 0.96862745 0.96862745]\n",
      "   [0.96862745 0.96862745 0.96862745]]\n",
      "\n",
      "  [[0.96862745 0.96862745 0.96862745]\n",
      "   [0.96862745 0.96862745 0.96862745]\n",
      "   [0.96862745 0.96862745 0.96862745]\n",
      "   ...\n",
      "   [0.96862745 0.96862745 0.96862745]\n",
      "   [0.96862745 0.96862745 0.96862745]\n",
      "   [0.96862745 0.96862745 0.96862745]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.96862745 0.96862745 0.96862745]\n",
      "   [0.96862745 0.96862745 0.96862745]\n",
      "   [0.96862745 0.96862745 0.96862745]\n",
      "   ...\n",
      "   [0.96862745 0.96862745 0.96862745]\n",
      "   [0.96862745 0.96862745 0.96862745]\n",
      "   [0.96862745 0.96862745 0.96862745]]\n",
      "\n",
      "  [[0.96862745 0.96862745 0.96862745]\n",
      "   [0.96862745 0.96862745 0.96862745]\n",
      "   [0.96862745 0.96862745 0.96862745]\n",
      "   ...\n",
      "   [0.96862745 0.96862745 0.96862745]\n",
      "   [0.96862745 0.96862745 0.96862745]\n",
      "   [0.96862745 0.96862745 0.96862745]]\n",
      "\n",
      "  [[0.96862745 0.96862745 0.96862745]\n",
      "   [0.96862745 0.96862745 0.96862745]\n",
      "   [0.96862745 0.96862745 0.96862745]\n",
      "   ...\n",
      "   [0.96862745 0.96862745 0.96862745]\n",
      "   [0.96862745 0.96862745 0.96862745]\n",
      "   [0.96862745 0.96862745 0.96862745]]]]\n",
      "[[[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]]\n",
      "[[[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]]\n",
      "[[[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]]\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "anchor = mh.adjust_im(anchor_path, (150, 150)) \n",
    "\n",
    "for i, file in enumerate(os.listdir(target_path)):\n",
    "    target = mh.adjust_im(os.path.join(target_path, file), (150, 150))\n",
    "    print(target)\n",
    "    anchor_embedding, positive_embedding, negative_embedding = (\n",
    "        embedding_model(tf.keras.applications.resnet.preprocess_input(anchor)),\n",
    "        embedding_model(tf.keras.applications.resnet.preprocess_input(target)),\n",
    "        embedding_model(tf.keras.applications.resnet.preprocess_input(target)),\n",
    "    )\n",
    "    cosine_similarity = tf.keras.metrics.CosineSimilarity()\n",
    "\n",
    "    positive_similarity = cosine_similarity(anchor_embedding, positive_embedding)\n",
    "    # print(\"Positive similarity:\", positive_similarity.numpy())\n",
    "\n",
    "    negative_similarity = cosine_similarity(anchor_embedding, negative_embedding)\n",
    "    # print(\"Negative similarity\", negative_similarity.numpy())\n",
    "\n",
    "    if positive_similarity > negative_similarity:\n",
    "        preds.append((i, positive_similarity))\n",
    "    else:    \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, <tf.Tensor: shape=(), dtype=float32, numpy=0.9999801>),\n",
       " (3, <tf.Tensor: shape=(), dtype=float32, numpy=0.99927205>),\n",
       " (4, <tf.Tensor: shape=(), dtype=float32, numpy=0.9978555>),\n",
       " (5, <tf.Tensor: shape=(), dtype=float32, numpy=0.9961332>),\n",
       " (6, <tf.Tensor: shape=(), dtype=float32, numpy=0.99452704>),\n",
       " (7, <tf.Tensor: shape=(), dtype=float32, numpy=0.9926253>),\n",
       " (8, <tf.Tensor: shape=(), dtype=float32, numpy=0.99123716>),\n",
       " (9, <tf.Tensor: shape=(), dtype=float32, numpy=0.98977554>),\n",
       " (10, <tf.Tensor: shape=(), dtype=float32, numpy=0.9885911>),\n",
       " (11, <tf.Tensor: shape=(), dtype=float32, numpy=0.98754096>),\n",
       " (12, <tf.Tensor: shape=(), dtype=float32, numpy=0.986044>),\n",
       " (13, <tf.Tensor: shape=(), dtype=float32, numpy=0.98574597>),\n",
       " (14, <tf.Tensor: shape=(), dtype=float32, numpy=0.98495156>),\n",
       " (15, <tf.Tensor: shape=(), dtype=float32, numpy=0.98449135>)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bangkit-ws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
