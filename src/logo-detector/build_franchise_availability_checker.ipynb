{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 01:16:34.021296: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-14 01:16:34.068299: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-14 01:16:34.068770: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-14 01:16:35.029406: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# import cv2 as cv\n",
    "# import numpy as np\n",
    "# import utils.model_helper as mh\n",
    "# import utils.data_utils as du\n",
    "import utils.metrics as M\n",
    "import tensorflow.keras.backend as K\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '/home/irizqy/ml_ws/bangkit-ws/data/bizz.it-sim_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_pairs, train_labels), (test_pairs, test_labels) = du.make_train_test_pairs(DATASET_PATH, .2, use_gray=False)\n",
    "train_pairs.shape, train_labels.shape, test_pairs.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_labels, return_counts=True), np.unique(test_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 20\n",
    "h = 15\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "columns = 8\n",
    "rows = 8\n",
    "for index, i in enumerate(range(1, (columns*rows +1)//2 + 1)):\n",
    "    img = test_pairs[index][0]\n",
    "    fig.add_subplot(rows, columns, 2*i - 1) \n",
    "    plt.title(test_labels[index])\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    img = test_pairs[index][1]\n",
    "    fig.add_subplot(rows, columns, 2*i)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (150, 150, 3)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = train_pairs.shape[0] // BATCH_SIZE\n",
    "test_step = test_pairs.shape[0] // BATCH_SIZE\n",
    "\n",
    "print(train_step, test_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseModel:\n",
    "\n",
    "    def __init__(self, input_shape, embedding_dim=224):\n",
    "        self.input_shape = input_shape\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "    def _build(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(32, (5, 5), activation='relu', input_shape=self.input_shape),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu',),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu',),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.Conv2D(128, (3, 3), activation='relu',),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(self.embedding_dim),\n",
    "            tf.keras.layers.Dropout(.2),\n",
    "        ])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm = SiameseModel(IMG_SHAPE)\n",
    "\n",
    "# featureExtractor = sm._build()\n",
    "\n",
    "base_cnn =  tf.keras.applications.resnet.ResNet50(\n",
    "    weights='imagenet', input_shape=IMG_SHAPE, include_top=False\n",
    ")\n",
    "\n",
    "# base_cnn.summary()\n",
    "\n",
    "cnn_model = base_cnn.get_layer('conv5_block3_2_conv')\n",
    "\n",
    "flatten = tf.keras.layers.GlobalAveragePooling2D()(cnn_model.output)\n",
    "dense_2 = tf.keras.layers.Dense(units=224)(flatten)\n",
    "\n",
    "featureExtractor = tf.keras.Model(base_cnn.input, dense_2)\n",
    "\n",
    "for layer in featureExtractor.layers[:-25]:\n",
    "    layer.trainable = False\n",
    "\n",
    "featureExtractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the siamese network\n",
    "print(\"[INFO] building siamese network...\")\n",
    "imgA = tf.keras.layers.Input(shape=IMG_SHAPE)\n",
    "imgB = tf.keras.layers.Input(shape=IMG_SHAPE)\n",
    "featsA = featureExtractor(imgA)\n",
    "featsB = featureExtractor(imgB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, construct the siamese network\n",
    "distance = tf.keras.layers.Lambda(lambda vectors: K.sqrt(K.maximum(K.sum(K.square(vectors[0] - vectors[1]), axis=1, keepdims=True), K.epsilon())))([featsA, featsB])\n",
    "# distance = tf.keras.layers.Lambda(M.euclidean_distance)([featsA, featsB])\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "model = tf.keras.Model(inputs=[imgA, imgB], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = tf.keras.callbacks.TensorBoard(log_dir='./log/', histogram_freq=0,  \n",
    "          write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "# compile the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(),\n",
    "\tmetrics=[\"accuracy\"])\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "history = model.fit(\n",
    "\t[train_pairs[:, 0], train_pairs[:, 1]], train_labels[:],\n",
    "\tvalidation_data=([test_pairs[:, 0], test_pairs[:, 1]], test_labels[:]),\n",
    "\tbatch_size=BATCH_SIZE,\n",
    "    callbacks=[tb],\n",
    "\tepochs=EPOCHS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(H):\n",
    "\t# construct a plot that plots and saves the training history\n",
    "\tplt.style.use(\"ggplot\")\n",
    "\tplt.figure()\n",
    "\tplt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
    "\tplt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
    "\tplt.plot(H.history[\"accuracy\"], label=\"train_acc\")\n",
    "\tplt.plot(H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "\tplt.title(\"Training Loss and Accuracy\")\n",
    "\tplt.xlabel(\"Epoch #\")\n",
    "\tplt.ylabel(\"Loss/Accuracy\")\n",
    "\tplt.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/home/irizqy/ml_ws/bangkit-ws/src/logo-detector/im_similar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 01:16:41.577103: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-14 01:16:41.577561: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('/home/irizqy/ml_ws/bangkit-ws/src/logo-detector/im_similar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_im1_1 = '/home/irizqy/ml_ws/bangkit-ws/src/logo-detector/cropped-logo0.jpg'\n",
    "path_im1_2 = '/home/irizqy/Downloads/franchise/ct.png'\n",
    "\n",
    "path_im2_1 = '/home/irizqy/Downloads/franchise/ct.png'\n",
    "path_im2_2 = '/home/irizqy/Downloads/sabana_10.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9861888]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im1 = mh.adjust_im(path_im2_2, (150, 150))\n",
    "im2 = mh.adjust_im(path_im2_2, (150, 150))\n",
    "\n",
    "model((im1, im2)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "BASE_TEST_PATH = '/home/irizqy/Downloads/franchise'\n",
    "test_data = os.listdir(BASE_TEST_PATH)\n",
    "\n",
    "im1 = mh.adjust_im(path_im2_2, (150, 150), use_gray=True)\n",
    "# im2 = mh.adjust_im(path_im2_2, (150, 150))\n",
    "\n",
    "# model.predict((im1, im2))[0][0]\n",
    "\n",
    "for file in test_data:\n",
    "    im2 = mh.adjust_im(os.path.join(BASE_TEST_PATH, file), (150, 150), use_gray=True)\n",
    "    pred = model.predict((im1, im2))[0][0]\n",
    "    preds.append(np.round(pred, 5))\n",
    "\n",
    "preds = np.asarray(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = np.argmax(preds)\n",
    "print(max_idx, preds[max_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{key: val.split('.')[0] for key, val in enumerate(test_data)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[max_idx]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bangkit-ws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
